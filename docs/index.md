# Exam topics

# CCP CFL-C02 Exam

#


[CCP CFL-C02 Exam 1](#_Toc146358846)

[Services: 15](#_Toc146358847)

[Analytics: 15](#_Toc146358848)

[Amazon Athena\* 15](#_Toc146358849)

[Amazon Athena 15](#_Toc146358850)

[AWS Data Exchange\* 15](#_Toc146358851)

[AWS Data Exchange 15](#_Toc146358852)

[Amazon EMR\* 15](#_Toc146358853)

[Amazon EMR Serverless 15](#_Toc146358854)

[AWS Glue\* 15](#_Toc146358855)

[AWS Glue 15](#_Toc146358856)

[Amazon Kinesis\* 16](#_Toc146358857)

[Amazon Kinesis 16](#_Toc146358858)

[Amazon Managed Streaming for Apache Kafka (Amazon MSK)\* 17](#_Toc146358859)

[Amazon MSK 17](#_Toc146358860)

[Amazon OpenSearch Service\* 17](#_Toc146358861)

[Amazon OpenSearch Service 17](#_Toc146358862)

[Amazon QuickSight\* 17](#_Toc146358863)

[Amazon QuickSight 17](#_Toc146358864)

[Amazon Redshift 17](#_Toc146358865)

[Amazon Redshift 17](#_Toc146358866)

[Application Integration: 17](#_Toc146358867)

[Amazon EventBridge\* 17](#_Toc146358868)

[Amazon EventBridge 17](#_Toc146358869)

[Amazon Simple Notification Service (Amazon SNS) 17](#_Toc146358870)

[Amazon Simple Notification Service (Amazon SNS 17](#_Toc146358871)

[Amazon Simple Queue Service (Amazon SQS) 18](#_Toc146358872)

[Amazon Simple Queue Service (Amazon SQS) 18](#_Toc146358873)

[AWS Step Functions\* 18](#_Toc146358874)

[AWS Step Functions 18](#_Toc146358875)

[Amazon Connect\* 18](#_Toc146358876)

[Amazon Connect 18](#_Toc146358877)

[Amazon Simple Email Service (Amazon SES)\* 18](#_Toc146358878)

[Amazon SES 18](#_Toc146358879)

[Cloud Financial Management: 18](#_Toc146358880)

[AWS Billing Conductor\* 18](#_Toc146358881)

[AWS Budgets 18](#_Toc146358882)

[Example: AWS Budgets: 18](#_Toc146358883)

[AWS Cost and Usage Report\* 19](#_Toc146358884)

[AWS Cost and Usage Reports (AWS CUR) 19](#_Toc146358885)

[AWS Cost and Usage Reports can do the following: 19](#_Toc146358886)

[AWS Cost Explorer 19](#_Toc146358887)

[AWS Cost Explorer 19](#_Toc146358888)

[AWS Marketplace 19](#_Toc146358889)

[AWS Marketplace 19](#_Toc146358890)

[Compute: 20](#_Toc146358891)

[AWS Batch\* 20](#_Toc146358892)

[Amazon EC2 20](#_Toc146358893)

[Amazon Elastic Compute Cloud (Amazon EC2) 20](#_Toc146358894)

[Amazon EC2 instance types 20](#_Toc146358895)

[1. General purpose instances 20](#_Toc146358896)

[2. Compute optimized instances 20](#_Toc146358897)

[3. Memory optimized instances 20](#_Toc146358898)

[4. Accelerated computing instances 20](#_Toc146358899)

[5. Storage optimized instances 20](#_Toc146358900)

[Amazon EC2 Instant Stores 21](#_Toc146358901)

[Amazon EC2 pricing 21](#_Toc146358902)

[1. On-Demand Instances 21](#_Toc146358903)

[**2.** Reserved Instances 21](#_Toc146358904)

[Standard Reserved Instances 21](#_Toc146358905)

[Convertible Reserved Instances 21](#_Toc146358906)

[3. EC2 Instance Savings Plans 22](#_Toc146358907)

[4. Spot Instances 22](#_Toc146358908)

[5. Dedicated Hosts 22](#_Toc146358909)

[Amazon EC2 Auto Scaling 22](#_Toc146358910)

[ Dynamic scaling 22](#_Toc146358911)

[ Predictive scaling 22](#_Toc146358912)

[Minimum capacity 22](#_Toc146358913)

[Desired capacity 22](#_Toc146358914)

[Maximum capacity 22](#_Toc146358915)

[Elastic Load Balancing 22](#_Toc146358916)

[Elastic Load Balancing 22](#_Toc146358917)

[AWS Elastic Beanstalk 23](#_Toc146358918)

[AWS Elastic Beanstalk 23](#_Toc146358919)

[Amazon LightSail\* 23](#_Toc146358920)

[Amazon LightSail 23](#_Toc146358921)

[AWS Local Zones\* 23](#_Toc146358922)

[AWS Local Zones 23](#_Toc146358923)

[AWS Outposts\* 23](#_Toc146358924)

[AWS Outposts 23](#_Toc146358925)

[AWS Outposts rack 24](#_Toc146358926)

[AWS Outposts servers 24](#_Toc146358927)

[AWS Wavelength\* 24](#_Toc146358928)

[AWS Wavelength 24](#_Toc146358929)

[Containers: 24](#_Toc146358930)

[Container 24](#_Toc146358931)

[Orchestration tools 24](#_Toc146358932)

[If you are trying to host traditional applications 24](#_Toc146358933)

[Amazon Elastic Container Registry (Amazon ECR)\* 24](#_Toc146358934)

[Amazon Elastic Container Service (Amazon ECS) 24](#_Toc146358935)

[Amazon Elastic Container Service (Amazon ECS) 24](#_Toc146358936)

[Amazon Elastic Kubernetes Service (Amazon EKS) 25](#_Toc146358937)

[Amazon Elastic Kubernetes Service (Amazon EKS) 25](#_Toc146358938)

[Customer Engagement: 25](#_Toc146358939)

[AWS Activate for Startups\* 25](#_Toc146358940)

[AWS IQ\* 25](#_Toc146358941)

[AWS Managed Services (AMS)\* 25](#_Toc146358942)

[AWS Support\* 25](#_Toc146358943)

[Database: 25](#_Toc146358944)

[Amazon Aurora 25](#_Toc146358945)

[Amazon Aurora 25](#_Toc146358946)

[Amazon DynamoDB 26](#_Toc146358947)

[Amazon DynamoDB 26](#_Toc146358948)

[Amazon DynamoDB Accelerator (DAX) 26](#_Toc146358949)

[Amazon MemoryDB for Redis\* 26](#_Toc146358950)

[Amazon Neptune 26](#_Toc146358951)

[Amazon Neptune 26](#_Toc146358952)

[Amazon RDS 26](#_Toc146358953)

[Amazon Relational Database Service (Amazon RDS) 26](#_Toc146358954)

[Amazon RDS database engines 27](#_Toc146358955)

[Developer Tools: 27](#_Toc146358956)

[AWS AppConfig\* 27](#_Toc146358957)

[AWS AppConfig 27](#_Toc146358958)

[AWS CLI\* 27](#_Toc146358959)

[AWS Command Line Interface (AWS CLI) 27](#_Toc146358960)

[AWS Cloud9\* 27](#_Toc146358961)

[AWS Cloud9 27](#_Toc146358962)

[AWS CloudShell\* 27](#_Toc146358963)

[AWS CloudShell 27](#_Toc146358964)

[AWS CodeArtifact\* 27](#_Toc146358965)

[CodeArtifact 27](#_Toc146358966)

[AWS CodeBuild\* 28](#_Toc146358967)

[AWS CodeBuild 28](#_Toc146358968)

[AWS CodeCommit\* 28](#_Toc146358969)

[AWS CodeCommit 28](#_Toc146358970)

[AWS CodeDeploy\* 28](#_Toc146358971)

[CodeDeploy 28](#_Toc146358972)

[AWS CodePipeline\* 28](#_Toc146358973)

[AWS CodePipeline 28](#_Toc146358974)

[AWS CodeStar\* 28](#_Toc146358975)

[AWS CodeStar 28](#_Toc146358976)

[AWS X-Ray\* 28](#_Toc146358977)

[End User Computing: 28](#_Toc146358978)

[Amazon AppStream 2.0\* 28](#_Toc146358979)

[AppStream 2.0 28](#_Toc146358980)

[Amazon WorkSpaces\* 28](#_Toc146358981)

[Amazon WorkSpaces 28](#_Toc146358982)

[Amazon WorkSpaces Web\* 28](#_Toc146358983)

[Amazon WorkSpaces Web 28](#_Toc146358984)

[Frontend Web and Mobile: 29](#_Toc146358985)

[AWS Amplify\* 29](#_Toc146358986)

[AWS Amplify 29](#_Toc146358987)

[AWS AppSync\* 29](#_Toc146358988)

[AWS AppSync 29](#_Toc146358989)

[AWS Device Farm\* 29](#_Toc146358990)

[AWS Device Farm 29](#_Toc146358991)

[Internet of Things (IoT): 29](#_Toc146358992)

[AWS IoT Core\* 29](#_Toc146358993)

[AWS IoT Core 29](#_Toc146358994)

[AWS IoT Greengrass\* 29](#_Toc146358995)

[AWS IoT Greengrass 29](#_Toc146358996)

[Machine Learning: 29](#_Toc146358997)

[Amazon Comprehend\* 29](#_Toc146358998)

[Amazon Comprehend 29](#_Toc146358999)

[Amazon Kendra\* 30](#_Toc146359000)

[Amazon Kendra 30](#_Toc146359001)

[Amazon Lex\* 30](#_Toc146359002)

[Amazon Lex 30](#_Toc146359003)

[Amazon Polly\* 30](#_Toc146359004)

[Amazon Polly 30](#_Toc146359005)

[Amazon Rekognition\* 30](#_Toc146359006)

[Amazon Rekognition 30](#_Toc146359007)

[Amazon SageMaker\* 30](#_Toc146359008)

[Amazon SageMaker 30](#_Toc146359009)

[Amazon Textract\* 30](#_Toc146359010)

[Amazon Textract 30](#_Toc146359011)

[Amazon Transcribe\* 31](#_Toc146359012)

[Amazon Transcribe 31](#_Toc146359013)

[Amazon Translate\* 31](#_Toc146359014)

[Amazon Translate 31](#_Toc146359015)

[Management and Governance: 31](#_Toc146359016)

[AWS Auto Scaling\* 31](#_Toc146359017)

[AWS Auto Scaling 31](#_Toc146359018)

[AWS CloudFormation 31](#_Toc146359019)

[AWS CloudFormation 31](#_Toc146359020)

[AWS CloudTrail 32](#_Toc146359021)

[AWS CloudTrail 32](#_Toc146359022)

[CloudTrail Insights 32](#_Toc146359023)

[Amazon CloudWatch 32](#_Toc146359024)

[Amazon CloudWatch 32](#_Toc146359025)

[CloudWatch alarms 33](#_Toc146359026)

[CloudWatch benefits 33](#_Toc146359027)

[AWS Compute Optimizer\* 33](#_Toc146359028)

[AWS Compute Optimizer 33](#_Toc146359029)

[AWS Config\* 34](#_Toc146359030)

[AWS Config 34](#_Toc146359031)

[AWS Control Tower\* 34](#_Toc146359032)

[AWS Control Tower 34](#_Toc146359033)

[AWS Health Dashboard\* 34](#_Toc146359034)

[AWS Health Dashboard 34](#_Toc146359035)

[AWS Launch Wizard\* 34](#_Toc146359036)

[AWS Launch Wizard 34](#_Toc146359037)

[AWS License Manager\* 34](#_Toc146359038)

[License Manager 34](#_Toc146359039)

[AWS Management Console 34](#_Toc146359040)

[The AWS Management Console 34](#_Toc146359041)

[AWS Organizations 35](#_Toc146359042)

[service control policies (SCPs) 35](#_Toc146359043)

[Organizational units (OU) 35](#_Toc146359044)

[Consolidated Billing 35](#_Toc146359045)

[AWS Resource Groups and Tag Editor\* 35](#_Toc146359046)

[Resource Groups 35](#_Toc146359047)

[Tags 35](#_Toc146359048)

[AWS Service Catalog\* 35](#_Toc146359049)

[AWS Service Catalog 35](#_Toc146359050)

[AWS Systems Manager\* 36](#_Toc146359051)

[AWS Systems Manager 36](#_Toc146359052)

[AWS Trusted Advisor 36](#_Toc146359053)

[AWS Trusted Advisor 36](#_Toc146359054)

[AWS Trusted Advisor dashboard 36](#_Toc146359055)

[Trusted Advisor 5 Pillars: 36](#_Toc146359056)

[1. Cost Optimization 36](#_Toc146359057)

[2. Performance 36](#_Toc146359058)

[3. Security 36](#_Toc146359059)

[4. Fault Tolerance 36](#_Toc146359060)

[5. Service Limits (quotas) 37](#_Toc146359061)

[AWS Well-Architected Tool 37](#_Toc146359062)

[AWS OpsWorks 37](#_Toc146359063)

[Migration and Transfer: 37](#_Toc146359064)

[AWS Application Discovery Service\* 37](#_Toc146359065)

[AWS Application Discovery Service 37](#_Toc146359066)

[AWS Application Migration Service\* 37](#_Toc146359067)

[AWS Application Migration Service 37](#_Toc146359068)

[AWS Database Migration Service (AWS DMS) 37](#_Toc146359069)

[AWS Database Migration Service (AWS DMS) 37](#_Toc146359070)

[Use Cases 38](#_Toc146359071)

[1. Development and test migration 38](#_Toc146359072)

[2. Database consolidation 38](#_Toc146359073)

[3. Continuous Replication 38](#_Toc146359074)

[AWS Migration Hub\* 38](#_Toc146359075)

[AWS Migration Hub 38](#_Toc146359076)

[AWS Schema Conversion Tool (AWS SCT)\* 38](#_Toc146359077)

[AWS Schema Conversion Tool (AWS SCT) 38](#_Toc146359078)

[AWS Snow Family 38](#_Toc146359079)

[AWS Snowcone 38](#_Toc146359080)

[Snowball Edge 38](#_Toc146359081)

[AWS Snowball offers two types of devices: 38](#_Toc146359082)

[Snowball Edge Storage Optimized 38](#_Toc146359083)

[Snowball Edge Compute Optimized 39](#_Toc146359084)

[AWS Snowmobile 39](#_Toc146359085)

[AWS Transfer Family\* 39](#_Toc146359086)

[AWS Transfer Family Managed File Transfer (MFT) 39](#_Toc146359087)

[SFTP stands for Secure Shell (SSH) File Transfer Protocol 39](#_Toc146359088)

[FTP stands for File Transfer Protocol 39](#_Toc146359089)

[FTPS stands for File Transfer Protocol over SSL 39](#_Toc146359090)

[Networking and Content Delivery: 40](#_Toc146359091)

[Amazon API Gateway\* 40](#_Toc146359092)

[Amazon API Gateway 40](#_Toc146359093)

[Amazon CloudFront 40](#_Toc146359094)

[Amazon CloudFront 40](#_Toc146359095)

[CloudFront benefits: 40](#_Toc146359096)

[Origins and Distributions: 40](#_Toc146359097)

[CloudFront uses Edge Locations and Regional Edge Caches: 40](#_Toc146359098)

[AWS Direct Connect 41](#_Toc146359099)

[AWS Direct Connect 41](#_Toc146359100)

[AWS Global Accelerator\* 41](#_Toc146359101)

[AWS Global Accelerator 41](#_Toc146359102)

[Amazon Route 53 41](#_Toc146359103)

[Amazon Route 53 41](#_Toc146359104)

[Route 53 performs three main functions: 41](#_Toc146359105)

[Domain registration 41](#_Toc146359106)

[Domain Name Service (DNS) 41](#_Toc146359107)

[Health checking – Route 53 41](#_Toc146359108)

[PolicyWhat it Does 41](#_Toc146359109)

[Simple 41](#_Toc146359110)

[Failover 41](#_Toc146359111)

[Geolocation 42](#_Toc146359112)

[Geoproximity 42](#_Toc146359113)

[Latency 42](#_Toc146359114)

[Multivalue answer 42](#_Toc146359115)

[Weighted 42](#_Toc146359116)

[Amazon VPC 42](#_Toc146359117)

[Amazon VPC 42](#_Toc146359118)

[Internet gateway (igw) 42](#_Toc146359119)

[Virtual private gateway 42](#_Toc146359120)

[AWS VPN\* 42](#_Toc146359121)

[AWS Client VPN 42](#_Toc146359122)

[AWS Client VPN 42](#_Toc146359123)

[AWS Site-to-Site VPN 42](#_Toc146359124)

[AWS Site-to-Site VPN 42](#_Toc146359125)

[Security, Identity, and Compliance: 43](#_Toc146359126)

[AWS Artifact 43](#_Toc146359127)

[AWS Artifact 43](#_Toc146359128)

[AWS Artifact Agreements 43](#_Toc146359129)

[AWS Artifact Reports 43](#_Toc146359130)

[AWS Audit Manager\* 43](#_Toc146359131)

[AWS Audit Manager 43](#_Toc146359132)

[AWS Certificate Manager (ACM)\* 44](#_Toc146359133)

[AWS Certificate Manager (ACM 44](#_Toc146359134)

[AWS CloudHSM\* 44](#_Toc146359135)

[AWS CloudHSM 44](#_Toc146359136)

[Amazon Cognito\* 44](#_Toc146359137)

[Amazon Cognito 44](#_Toc146359138)

[Amazon Detective\* 44](#_Toc146359139)

[Amazon Detective 44](#_Toc146359140)

[AWS Directory Service\* 44](#_Toc146359141)

[AWS Directory Service 44](#_Toc146359142)

[AWS Firewall Manager\* 44](#_Toc146359143)

[AWS Firewall Manager 44](#_Toc146359144)

[Amazon GuardDuty 44](#_Toc146359145)

[Amazon GuardDuty 44](#_Toc146359146)

[AWS Identity and Access Management (IAM) 45](#_Toc146359147)

[AWS Identity and Access Management (IAM) 45](#_Toc146359148)

[AWS account Root User 45](#_Toc146359149)

[Root User Best practice: 45](#_Toc146359150)

[IAM users 45](#_Toc146359151)

[IAM user 45](#_Toc146359152)

[IAM User Best practice: 45](#_Toc146359153)

[IAM policies 45](#_Toc146359154)

[IAM policy 45](#_Toc146359155)

[IAM policies Best practice: 46](#_Toc146359156)

[IAM groups 46](#_Toc146359157)

[IAM group 46](#_Toc146359158)

[IAM Roles 46](#_Toc146359159)

[IAM Roles Best practice: 46](#_Toc146359160)

[Multi-factor authentication 46](#_Toc146359161)

[AWS IAM Identity Center (Successor AWS Single Sign-On)\* 46](#_Toc146359162)

[AWS IAM Identity Center 46](#_Toc146359163)

[Amazon Inspector 47](#_Toc146359164)

[AWS Key Management Service (AWS KMS) 47](#_Toc146359165)

[AWS Key Management Service (AWS KMS) 47](#_Toc146359166)

[Amazon Macie\* 47](#_Toc146359167)

[Amazon Macie 47](#_Toc146359168)

[AWS Network Firewall\* 47](#_Toc146359169)

[AWS Network Firewall 47](#_Toc146359170)

[AWS Resource Access Manager (AWS RAM)\* 47](#_Toc146359171)

[AWS Resource Access Manager (AWS RAM) 47](#_Toc146359172)

[AWS Secrets Manager\* 47](#_Toc146359173)

[AWS Secrets Manager 47](#_Toc146359174)

[AWS Security Hub\* 48](#_Toc146359175)

[AWS Security Hub 48](#_Toc146359176)

[AWS Shield 48](#_Toc146359177)

[AWS Shield 48](#_Toc146359178)

[AWS Shield Standard 48](#_Toc146359179)

[AWS Shield Advanced 48](#_Toc146359180)

[AWS WAF 48](#_Toc146359181)

[AWS WAF 48](#_Toc146359182)

[Serverless: 49](#_Toc146359183)

[Serverless means 49](#_Toc146359184)

[AWS Fargate 49](#_Toc146359185)

[AWS Fargate 49](#_Toc146359186)

[AWS Lambda 49](#_Toc146359187)

[AWS Lambda 49](#_Toc146359188)

[Storage: 49](#_Toc146359189)

[AWS Backup\* 49](#_Toc146359190)

[AWS Backup 49](#_Toc146359191)

[Amazon Elastic Block Store (Amazon EBS) 49](#_Toc146359192)

[Amazon Elastic Block Store 49](#_Toc146359193)

[Amazon EBS snapshots 50](#_Toc146359194)

[EBS snapshot 50](#_Toc146359195)

[Amazon Elastic File System (Amazon EFS) 50](#_Toc146359196)

[Amazon Elastic File System (Amazon EFS) 50](#_Toc146359197)

[AWS Elastic Disaster Recovery\* 50](#_Toc146359198)

[AWS Elastic Disaster Recovery 50](#_Toc146359199)

[Amazon FSx\* 50](#_Toc146359200)

[Amazon FSx 50](#_Toc146359201)

[Amazon S3 50](#_Toc146359202)

[Amazon Simple Storage Service (Amazon S3 50](#_Toc146359203)

[S3 Charges: 50](#_Toc146359204)

[Typical use cases include: 51](#_Toc146359205)

[ Backup and Storage 51](#_Toc146359206)

[ Application Hosting 51](#_Toc146359207)

[ Media Hosting 51](#_Toc146359208)

[ Software Delivery 51](#_Toc146359209)

[ Static Website 51](#_Toc146359210)

[Amazon S3 storage classes 51](#_Toc146359211)

[1. S3 Standard 51](#_Toc146359212)

[2. S3 Standard-Infrequent Access (S3 Standard-IA) 51](#_Toc146359213)

[3. S3 One Zone-Infrequent Access (S3 One Zone-IA) 51](#_Toc146359214)

[4. S3 Intelligent-Tiering 51](#_Toc146359215)

[5. S3 Glacier Instant Retrieval 52](#_Toc146359216)

[6. S3 Glacier Flexible Retrieval 52](#_Toc146359217)

[7. S3 Glacier Deep Archive 52](#_Toc146359218)

[8. S3 Outposts 52](#_Toc146359219)

[AWS Storage Gateway\* 52](#_Toc146359220)

[AWS Storage Gateway 52](#_Toc146359221)

[AWS Global Infrastructure: 52](#_Toc146359222)

[Regions & Availability Zones: 52](#_Toc146359223)

[Some key points about Regions. 52](#_Toc146359224)

[Selecting a Region 53](#_Toc146359225)

[1. Compliance with data governance and legal requirements 53](#_Toc146359226)

[2. Proximity to your customers 53](#_Toc146359227)

[3. Available services within a Region 53](#_Toc146359228)

[4. Pricing 53](#_Toc146359229)

[Availability Zones 53](#_Toc146359230)

[Edge Locations 53](#_Toc146359231)

[An edge location 53](#_Toc146359232)

[Interacting with AWS Services: 53](#_Toc146359233)

[The AWS Management Console 53](#_Toc146359234)

[The AWS Command Line Interface or CLI 54](#_Toc146359235)

[The AWS Software Development Kits or SDKs 54](#_Toc146359236)

[Summaries 54](#_Toc146359237)

[What is Cloud Computing: 54](#_Toc146359238)

[Cloud Computing Models 54](#_Toc146359239)

[Infrastructure as a Service (IaaS) 54](#_Toc146359240)

[Platform as a Service (PaaS) 54](#_Toc146359241)

[Software as a Service (SaaS) 55](#_Toc146359242)

[Advantages of cloud computing 55](#_Toc146359243)

[six advantages of cloud computing: 55](#_Toc146359244)

[1. Trade upfront expense for variable expense. 55](#_Toc146359245)

[2. Benefit from massive economies of scale. 55](#_Toc146359246)

[3. Stop guessing capacity. 55](#_Toc146359247)

[4. Increase speed and agility. 56](#_Toc146359248)

[5. Stop spending money running and maintaining data centers. 56](#_Toc146359249)

[6. Go global in minutes. 56](#_Toc146359250)

[3 common types of cloud deployment: 56](#_Toc146359251)

[1. Public Cloud 56](#_Toc146359252)

[2. Hybrid Cloud 56](#_Toc146359253)

[3. Private Cloud (on-premises) 56](#_Toc146359254)

[Public Cloud 56](#_Toc146359255)

[Hybrid 56](#_Toc146359256)

[On-premises 56](#_Toc146359257)

[Compute in the cloud: 56](#_Toc146359258)

[AWS Global Infrastructure: 57](#_Toc146359259)

[Networking: 57](#_Toc146359260)

[Network Hardening 57](#_Toc146359261)

[network ACLs 58](#_Toc146359262)

[security groups 58](#_Toc146359263)

[Security Group and a Network ACL Key Differences: 58](#_Toc146359264)

[Subnets 59](#_Toc146359265)

[Public subnets 59](#_Toc146359266)

[Private subnets 59](#_Toc146359267)

[Domain Name System (DNS) 59](#_Toc146359268)

[Storage and Databases: 59](#_Toc146359269)

[Storage 59](#_Toc146359270)

[Amazon S3 and Amazon EBS Key Differences: 59](#_Toc146359271)

[S3 59](#_Toc146359272)

[EBS 59](#_Toc146359273)

[Use Cases 59](#_Toc146359274)

[Amazon EBS and Amazon EFS Key Differences: 60](#_Toc146359275)

[EBS Vs EFS 60](#_Toc146359276)

[Amazon EBS 60](#_Toc146359277)

[Amazon EFS 60](#_Toc146359278)

[Databases 60](#_Toc146359279)

[Relational databases 60](#_Toc146359280)

[Lift-and-Shift 61](#_Toc146359281)

[Relational databases Vs Nonrelational databases 61](#_Toc146359282)

[Nonrelational databases 61](#_Toc146359283)

[Amazon RDS and Amazon DynamoDB Key Differences: 61](#_Toc146359284)

[Amazon RDS 61](#_Toc146359285)

[Amazon RDS Vs Amazon DynamoDB 61](#_Toc146359286)

[Amazon DynamoDB 61](#_Toc146359287)

[Use Cases 61](#_Toc146359288)

[Security 61](#_Toc146359289)

[Shared Responsibility Model: 61](#_Toc146359290)

[AWS: Security **of** the cloud 62](#_Toc146359291)

[Customers: Security **in** the cloud 62](#_Toc146359292)

[Amazon Web Services (AWS) Security **of** the cloud 62](#_Toc146359293)

[Customers: Security **in** the cloud 62](#_Toc146359294)

[Encryption 62](#_Toc146359295)

[Compliance 62](#_Toc146359296)

[AWS Compliance Center 63](#_Toc146359297)

[AWS compliance uses third-party auditors 63](#_Toc146359298)

[Denial-of-Service Attacks 63](#_Toc146359299)

[Distributed denial-of-service attacks 63](#_Toc146359300)

[IAM 63](#_Toc146359301)

[AWS Organizations 64](#_Toc146359302)

[Monitoring and Analytics 64](#_Toc146359303)

[Example: AWS CloudTrail event 64](#_Toc146359304)

[CloudWatch 64](#_Toc146359305)

[CloudTrail 64](#_Toc146359306)

[Trusted Advisor 64](#_Toc146359307)

[Pricing and Support 64](#_Toc146359308)

[Pricing 64](#_Toc146359309)

[AWS Free Tier 64](#_Toc146359310)

[The AWS Free Tier 64](#_Toc146359311)

[Always Free 64](#_Toc146359312)

[12 Months Free 65](#_Toc146359313)

[Trials 65](#_Toc146359314)

[Pay for what you use 65](#_Toc146359315)

[Pay less when you reserve. 65](#_Toc146359316)

[Pay less with volume-based discounts when you use more. 65](#_Toc146359317)

[AWS Pricing Calculator 65](#_Toc146359318)

[The AWS Pricing Calculator 65](#_Toc146359319)

[Pricing Examples: 65](#_Toc146359320)

[AWS Billing & Cost Management dashboard 66](#_Toc146359321)

[Support Plans 66](#_Toc146359322)

[AWS Support 66](#_Toc146359323)

[Basic Support 66](#_Toc146359324)

[Developer Support 67](#_Toc146359325)

[Business Support 67](#_Toc146359326)

[Enterprise On-Ramp Support 67](#_Toc146359327)

[Enterprise Support 68](#_Toc146359328)

[Developer, Business, Enterprise On-Ramp, and Enterprise Support 68](#_Toc146359329)

[Technical Account Manager (TAM) 68](#_Toc146359330)

[Migration and Innovation 69](#_Toc146359331)

[AWS Cloud Adoption Framework 69](#_Toc146359332)

[Business Perspective 69](#_Toc146359333)

[People Perspective 69](#_Toc146359334)

[Governance Perspective 69](#_Toc146359335)

[Platform Perspective 70](#_Toc146359336)

[Security Perspective 70](#_Toc146359337)

[Operations Perspective 70](#_Toc146359338)

[Migration Strategies 70](#_Toc146359339)

[7 strategies for migration 70](#_Toc146359340)

[Rehosting 71](#_Toc146359341)

[Replatforming 71](#_Toc146359342)

[Retire 71](#_Toc146359343)

[Retain 71](#_Toc146359344)

[Repurchase 71](#_Toc146359345)

[Refactoring 71](#_Toc146359346)

[The Cloud Journey 71](#_Toc146359347)

[The AWS Well-Architected Framework 71](#_Toc146359348)

[The Well-Architected Framework is based on six pillars: 71](#_Toc146359349)

[Operational excellence Pillar 72](#_Toc146359350)

[Reliability Pillar 72](#_Toc146359351)

[Performance efficiency Pillar 72](#_Toc146359352)

[Cost optimization Pillar 72](#_Toc146359353)

[Sustainability Pillar 72](#_Toc146359354)

##

## Services:

## Analytics:

### Amazon Athena\*

_Amazon Athena_ is a serverless, interactive analytics service built on open-source frameworks, supporting open-table and file formats. Athena provides a simplified, flexible way to analyze petabytes of data where it lives. Analyze data or build applications from an Amazon Simple Storage Service (S3) data lake and 30 data sources, including on-premises data sources or other cloud systems using SQL or Python. Athena is built on open-source Trino and Presto engines and Apache Spark frameworks, with no provisioning or configuration effort required.

### AWS Data Exchange\*

_AWS Data Exchange_ makes it easy for AWS customers to securely exchange and use third-party data on AWS. Data analysts, product managers, portfolio managers, data scientists, quants, clinical trial technicians, and developers in nearly every industry would like access to more data to drive analytics, train machine learning (ML) models, and make data-driven decisions. But there is no one place to find data from multiple providers and no consistency in how providers deliver data, leaving them to deal with a mix of shipped physical media, FTP credentials, and bespoke API calls. Conversely, many organizations would like to make their data available for either research or commercial purposes, but it's too hard and expensive to build and maintain data delivery, entitlement, and billing technology, which further depresses the supply of valuable data.

### Amazon EMR\*

_Amazon EMR Serverless_ is a new option in Amazon EMR that makes it easy and cost-effective for data engineers and analysts to run applications built using open source big data frameworks such as Apache Spark, Hive or Presto, without having to tune, operate, optimize, secure or manage clusters.

A managed cluster platform for running big data frameworks like Apache Spark and Hadoop.

### AWS Glue\*

_AWS Glue_ Preparing your data to obtain quality results is the first step in an analytics or ML project. AWS Glue is a serverless data integration service that makes data preparation simpler, faster, and cheaper. You can discover and connect to over 70 diverse data sources, manage your data in a centralized data catalog, and visually create, run, and monitor ETL pipelines to load data into your data lakes.

AWS Glue is a fully managed, pay-as-you-go, extract, transform, and load (ETL) service that automates the time-consuming steps of data preparation for analytics.

AWS Glue automatically discovers and profiles data via the Glue Data Catalog, recommends and generates ETL code to transform your source data into target schemas.

AWS Glue runs the ETL jobs on a fully managed, scale-out Apache Spark environment to load your data into its destination.

AWS Glue also allows you to setup, orchestrate, and monitor complex data flows.

You can create and run an ETL job with a few clicks in the AWS Management Console.

Use AWS Glue to discover properties of data, transform it, and prepare it for analytics.

Glue can automatically discover both structured and semi-structured data stored in data lakes on [Amazon S3](https://aws.amazon.com/s3/), data warehouses in [Amazon Redshift](https://aws.amazon.com/redshift/), and various databases running on AWS.

It provides a unified view of data via the Glue Data Catalog that is available for ETL, querying and reporting using services like [Amazon Athena](https://aws.amazon.com/athena/), [Amazon EMR](https://aws.amazon.com/emr/), and [Amazon Redshift Spectrum](https://aws.amazon.com/redshift/).

Glue automatically generates Scala or Python code for ETL jobs that you can further customize using tools you are already familiar with.

AWS Glue is serverless, so there are no compute resources to configure and manage.

### Amazon Kinesis\*

_Amazon Kinesis_ Collect, process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information.

Ingest real-time data such as video, audio, application logs, website clickstreams, and IoT telemetry data for machine learning, analytics, and other applications.

Process and analyze data as it arrives and respond instantly instead of having to wait until all your data is collected before the processing can begin.

Amazon Kinesis makes it easy to collect, process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information.

Collection of services for processing streams of various data.

Data is processed in "shards".

There are four types of Kinesis service, and these are detailed below.

1. Kinesis Video Streams
2. Kinesis Data Streams
3. Kinesis Data Firehose
4. Kinesis Data Analytics

### Amazon Managed Streaming for Apache Kafka (Amazon MSK)\*

_Amazon MSK_ makes it easy to ingest and process streaming data in real time with fully managed Apache Kafka

### Amazon OpenSearch Service\*

_Amazon OpenSearch Service_ is a managed service that makes it easy for you to perform interactive log analytics, real-time application monitoring, website search, and more.

### Amazon QuickSight\*

_Amazon QuickSight_ is a very fast, easy-to-use, cloud-powered business analytics service that makes it easy for all employees within an organization to build visualizations, perform ad-hoc analysis, and quickly get business insights from their data, anytime, on any device. Upload CSV and Excel files; connect to SaaS applications like Salesforce; access on-premises databases like SQL Server, MySQL, and PostgreSQL; and seamlessly discover your AWS data sources such as Amazon Redshift, Amazon RDS, Amazon Aurora, Amazon Athena, and Amazon S3. QuickSight enables organizations to scale their business analytics capabilities to hundreds of thousands of users, and delivers fast and responsive query performance by using a robust in-memory engine (SPICE).

### Amazon Redshift

### Amazon Redshift

is a data warehousing service that you can use for big data analytics. It offers the ability to collect data from many sources and helps you to understand relationships and trends across your data. It's massively scalable. Redshift nodes in multiple petabyte sizes is very common. In fact, in cooperation with Amazon Redshift Spectrum, you can directly run a single SQL query against exabytes of unstructured data running in data lakes. Redshift uses a variety of innovations that allow you to achieve up to 10 times higher performance than traditional databases, when it comes to these kinds of business intelligence workloads. The key for you is to understand that when you need big data BI solutions, Redshift allows you to get started with a single API call. Less time waiting for results, more time getting answers.

## Application Integration:

### Amazon EventBridge\*

_Amazon EventBridge_ makes it easier to build event-driven applications at scale using events generated from your applications, integrated SaaS applications, and AWS services.

To get started, you can choose an event source on the EventBridge console. You can then select a target from AWS services including AWS Lambda, Amazon Simple Notification Service (SNS), and Amazon Kinesis Data Firehose. EventBridge will automatically deliver the events in near real-time.

### Amazon Simple Notification Service (Amazon SNS)

### Amazon Simple Notification Service (Amazon SNS

is a publish/subscribe service. Using Amazon SNS topics, a publisher publishes messages to subscribers. This is similar to the coffee shop; the cashier provides coffee orders to the barista who makes the drinks.

In Amazon SNS, subscribers can be web servers, email addresses, AWS Lambda functions, or several other options.

### Amazon Simple Queue Service (Amazon SQS)

### Amazon Simple Queue Service (Amazon SQS)

is a message queuing service. Using Amazon SQS, you can send, store, and receive messages between software components, without losing messages or requiring other services to be available. In Amazon SQS, an application sends messages into a queue. A user or service retrieves a message from the queue, processes it, and then deletes it from the queue.

### AWS Step Functions\*

_AWS Step Functions_ is a fully managed service that makes it easier to coordinate the components of distributed applications and microservices using visual workflows. Building applications from individual components that each perform a discrete function helps you scale more easily and change applications more quickly.

Step Functions is a reliable way to coordinate components and step through the functions of your application. Step Functions provides a graphical console to arrange and visualize the components of your application as a series of steps. This makes it easier to build and run multi-step applications.

Step Functions automatically triggers and tracks each step and retries when there are errors, so your application executes in order and as expected. Step Functions logs the state of each step, so when things do go wrong, you can diagnose and debug problems more quickly. You can change and add steps without even writing code, so you can more easily evolve your application and innovate faster. Business Applications:

### Amazon Connect\*

_Amazon Connect_ is an omnichannel cloud contact center. You can set up a contact center in a few steps, add agents who are located anywhere, and start engaging with your customers. You can create personalized experiences for your customers using omnichannel communications.

### Amazon Simple Email Service (Amazon SES)\*

_Amazon SES_ is a cloud-based email service provider that can integrate into any application for high volume email automation. Whether you use an email software to send transactional emails, marketing emails, or newsletter emails, you pay only for what you use.

## Cloud Financial Management:

### AWS Billing Conductor\*

AWS Billing Conductor is a custom billing service that can support the show back and chargeback workflows of AWS Solution Providers and Enterprise customers. Using AWS Billing Conductor, you can customize a second, alternative version of your monthly billing data.

### AWS Budgets

In _AWS Budgets_ you can create budgets to plan your service usage, service costs, and instance reservations. The information in AWS Budgets updates three times a day. This helps you to accurately determine how close your usage is to your budgeted amounts or to the AWS Free Tier limits. In AWS Budgets, you can also set custom alerts when your usage exceeds (or is forecasted to exceed) the budgeted amount.

#### Example: AWS Budgets:

Suppose that you have set a budget for Amazon EC2. You want to ensure that your company's usage of Amazon EC2 does not exceed $200 for the month.

In AWS Budgets, you could set a custom budget to notify you when your usage has reached half of this amount ($100). This setting would allow you to receive an alert and decide how you would like to proceed with your continued use of Amazon EC2.

### AWS Cost and Usage Report\*

_AWS Cost and Usage Reports (AWS CUR)_ contains the most comprehensive set of cost and usage data available. You can use Cost and Usage Reports to publish your AWS billing reports to an Amazon Simple Storage Service (Amazon S3) bucket that you own. You can receive reports that break down your costs by the hour, day, or month, by product or product resource, or by tags that you define yourself. AWS updates the report in your bucket once a day in comma-separated value (CSV) format. You can view the reports using spreadsheet software such as Microsoft Excel or Apache OpenOffice Calc, or access them from an application using the Amazon S3 API.

AWS Cost and Usage Reports tracks your AWS usage and provides estimated charges associated with your account. Each report contains line items for each unique combination of AWS products, usage type, and operation that you use in your AWS account. You can customize the AWS Cost and Usage Reports to aggregate the information either by the hour, day, or month.

#### AWS Cost and Usage Reports can do the following:

- Deliver report files to your Amazon S3 bucket
- Update the report up to three times a day
- Create, retrieve, and delete your reports using the AWS CUR API Reference

### AWS Cost Explorer

_AWS Cost Explorer_ is a tool that lets you visualize, understand, and manage your AWS costs and usage over time.

AWS Cost Explorer includes a default report of the costs and usage for your top five cost-accruing AWS services. You can apply custom filters and groups to analyze your data. For example, you can view resource usage at the hourly level. It will show you which services you are spending the most money on, and it gives you 12 months of historical data.

One important grouping to note is to group by tag. Many resources in AWS are taggable. Tags are essentially user-defined key-value pairs. So you can tag an EC2 instance with a specific project name or a database with the same project name, and then you can come into the AWS Cost Explorer, filter by tag, and see all of the expenses associated with that tag. Cost Explorer also allows you to create custom reports.

Cost Explorer gives you some powerful defaults for reports, but you can build your own custom ones as well. This will help you identify cost drivers and take action when necessary to curb spending. Cost optimization is a priority you should be paying close attention to, and you can use the Cost Explorer to help get you going in the right direction.

### AWS Marketplace

_AWS Marketplace_ is a digital catalog that includes thousands of software listings from independent software vendors. You can use AWS Marketplace to find, test, and buy software that runs on AWS.

For each listing in AWS Marketplace, you can access detailed information on pricing options, available support, and reviews from other AWS customers.

You can also explore software solutions by industry and use case. For example, suppose your company is in the healthcare industry. In AWS Marketplace, you can review use cases that software helps you to address, such as implementing solutions to protect patient records or using machine learning models to analyze a patient's medical history and predict possible health risks.

## Compute:

### AWS Batch\*

WS Batch is a set of batch management capabilities that enables developers, scientists, and engineers to easily and efficiently run hundreds of thousands of batch computing jobs on AWS.

### Amazon EC2

Amazon Elastic Compute Cloud (Amazon EC2)provides secure, resizable compute capacity in the cloud as Amazon EC2 instances. EC2s are virtual Macines. EC2 is a service that lets you run virtual servers in the cloud. If you have applications that you want to run in Amazon EC2, you must do the following:

1. Provision instances (virtual servers).
2. Upload your code.
3. Continue to manage the instances while your application is running.

_Amazon EC2 instance types_are optimized for different tasks. When selecting an instance type, consider the specific needs of your workloads and applications. This might include requirements for compute, memory, or storage capabilities.

1. General purpose instances provide a balance of compute, memory, and networking resources. You can use them for a variety of workloads, such as:
  1. application servers
  2. gaming servers
  3. backend servers for enterprise applications
  4. small and medium databases
2. Compute optimized instances are ideal for compute-bound applications that benefit from high-performance processors. Like general purpose instances, you can use compute optimized instances for workloads such as web, application, and gaming servers.

However, the difference is compute optimized applications are ideal for high-performance web servers, compute-intensive applications servers, and dedicated gaming servers. You can also use compute optimized instances for batch processing workloads that require processing many transactions in a single group.

1. Memory optimized instances are designed to deliver fast performance for workloads that process large datasets in memory. In computing, memory is a temporary storage area. It holds all the data and instructions that a central processing unit (CPU) needs to be able to complete actions. Before a computer program or application is able to run, it is loaded from storage into memory. This preloading process gives the CPU direct access to the computer program.
2. Accelerated computing instances use hardware accelerators, or coprocessors, to perform some functions more efficiently than is possible in software running on CPUs. Examples of these functions include floating-point number calculations, graphics processing, and data pattern matching.
3. Storage optimized instances are designed for workloads that require high, sequential read and write access to large datasets on local storage. Examples of workloads suitable for storage optimized instances include distributed file systems, data warehousing applications, and high-frequency online transaction processing (OLTP) systems.

#### Amazon EC2 Instant Stores

An _instance store_ provides temporary block-level storage for an Amazon EC2 instance. An instance store is disk storage that is physically attached to the host computer for an EC2 instance, and therefore has the same lifespan as the instance. When the instance is terminated, you lose any data in the instance store.

Amazon EC2 instances are virtual servers. If you start an instance from a stopped state, the instance might start on another host, where the previously used instance store volume does not exist. Therefore, AWS recommends instance stores for use cases that involve temporary data that you do not need in the long term.

#### Amazon EC2 pricing

With Amazon EC2, you pay only for the compute time that you use. Amazon EC2 offers a variety of pricing options for different use cases. For example, if your use case can withstand interruptions, you can save with Spot Instances. You can also save by committing early and locking in a minimum level of use with Reserved Instances.

1. On-Demand Instances are ideal for short-term, irregular workloads that cannot be interrupted. No upfront costs or minimum contracts apply. The instances run continuously until you stop them, and you pay for only the compute time you use.
2. Reserved Instances ** ** are a billing discount applied to the use of On-Demand Instances in your account. There are two available types of Reserved Instances:

- **Standard Reserved Instances**
- **Convertible Reserved Instances**

Standard Reserved Instances: This option is a good fit if you know the EC2 instance type and size you need for your steady-state applications and in which AWS Region you plan to run them. Reserved Instances require you to state the following qualifications:

- **Instance type and size: ** For example, m5.xlarge
- **Platform description (operating system):** For example, Microsoft Windows Server or Red Hat Enterprise Linux
- **Tenancy:**  Default tenancy or dedicated tenancyYou have the option to specify an Availability Zone for your EC2 Reserved Instances. If you make this specification, you get EC2 capacity reservation. This ensures that your desired amount of EC2 instances will be available when you need them.

Convertible Reserved Instances: If you need to run your EC2 instances in different Availability Zones or different instance types, then Convertible Reserved Instances might be right for you. Note: You trade in a deeper discount when you require flexibility to run your EC2 instances.

At the end of a Reserved Instance term, you can continue using the Amazon EC2 instance without interruption. However, you are charged On-Demand rates until you do one of the following:

- Terminate the instance.
- Purchase a new Reserved Instance that matches the instance attributes (instance family and size, Region, platform, and tenancy).

1. EC2 Instance Savings Plans reduce your EC2 instance costs when you make an hourly spend commitment to an instance family and Region for a 1-year or 3-year term. This term commitment results in savings of up to 72 percent compared to On-Demand rates. Any usage up to the commitment is charged at the discounted Savings Plans rate (for example, $10 per hour). Any usage beyond the commitment is charged at regular On-Demand rates.

The EC2 Instance Savings Plans are a good option if you need flexibility in your Amazon EC2 usage over the duration of the commitment term. You have the benefit of saving costs on running any EC2 instance within an EC2 instance family in a chosen Region (for example, M5 usage in N. Virginia) regardless of Availability Zone, instance size, OS, or tenancy. The savings with EC2 Instance Savings Plans are similar to the savings provided by Standard Reserved Instances.

1. Spot Instances are ideal for workloads with flexible start and end times, or that can withstand interruptions. Spot Instances use unused Amazon EC2 computing capacity and offer you cost savings at up to 90% off of On-Demand prices.
2. Dedicated Hosts ** ** are physical servers with Amazon EC2 instance capacity that is fully dedicated to your use.

You can use your existing per-socket, per-core, or per-VM software licenses to help maintain license compliance. You can purchase On-Demand Dedicated Hosts and Dedicated Hosts Reservations. Of all the Amazon EC2 options that were covered, Dedicated Hosts are the most expensive.

#### Amazon EC2 Auto Scaling

**Scalability**  involves beginning with only the resources you need and designing your architecture to automatically respond to changing demand by scaling out or in. As a result, you pay for only the resources you use. You don't have to worry about a lack of computing capacity to meet your customers' needs.

If you wanted the scaling process to happen automatically, which AWS service would you use? The AWS service that provides this functionality for Amazon EC2 instances is Amazon EC2 Auto Scaling.

Within Amazon EC2 Auto Scaling, you can use two approaches: dynamic scaling and predictive scaling.

- Dynamic scaling responds to changing demand.
- Predictive scaling automatically schedules the right number of Amazon EC2 instances based on predicted demand

Minimum capacity is the number of Amazon EC2 instances that launch immediately after you have created the Auto Scaling group.

Desired capacity you can set the  **desired capacity** at two Amazon EC2 instances even though your application needs a minimum of a single Amazon EC2 instance to run.

Maximum capacity for example, you might configure the Auto Scaling group to scale out in response to increased demand, but only to a maximum of four Amazon EC2 instances.

#### Elastic Load Balancing

Elastic Load Balancing is the AWS service that automatically distributes incoming application traffic across multiple resources, such as Amazon EC2 instances.

A load balancer acts as a single point of contact for all incoming web traffic to your Auto Scaling group. This means that as you add or remove Amazon EC2 instances in response to the amount of incoming traffic, these requests route to the load balancer first. Then, the requests spread across multiple resources that will handle them. For example, if you have multiple Amazon EC2 instances, Elastic Load Balancing distributes the workload across the multiple instances so that no single instance has to carry the bulk of it.

Although Elastic Load Balancing and Amazon EC2 Auto Scaling are separate services, they work together to help ensure that applications running in Amazon EC2 can provide high performance and availability.

### AWS Elastic Beanstalk

_AWS Elastic Beanstalk_ is a service that helps you provision Amazon EC2-based environments. Instead of clicking around the console or writing multiple commands to build out your network, EC2 instances, scaling and Elastic Load Balancers, you can instead provide your application code and desired configurations to the AWS Elastic Beanstalk service, which then takes that information and builds out your environment for you. AWS Elastic Beanstalk also makes it easy to save environment configurations, so they can be deployed again easily. AWS Elastic Beanstalk gives you the convenience of not having to provision and manage all of these pieces separately, while still giving you the visibility and control of the underlying resources. You get to focus on your business application, not the infrastructure.

With AWS Elastic Beanstalk, you provide code and configuration settings, and Elastic Beanstalk deploys the resources necessary to perform the following tasks:

- Adjust capacity
- Load balancing
- Automatic scaling
- Application health monitoring

### Amazon LightSail\*

_Amazon LightSail_ Build applications and websites fast with pre-configured cloud resources

- Lightsail gets you started quickly with preconfigured Linux and Windows application stacks and an intuitive management console.
- Focus on your code, not your bill. Lightsail bundles all the resources you need into a single, simple price.
- Lightsail automatically configures networking, access, and security environments, taking the guesswork out of launching your server.

### AWS Local Zones\*

_AWS Local Zones_ allow you to use select AWS services, like compute and storage services, closer to more end-users, providing them very low latency access to the applications running locally. AWS Local Zones are also connected to the parent region via Amazon's redundant and very high bandwidth private network, giving applications running in AWS Local Zones fast, secure, and seamless access to the rest of AWS services.

### AWS Outposts\*

_AWS Outposts_ is a family of fully managed solutions delivering AWS infrastructure and services to virtually any on-premises or edge location for a truly consistent hybrid experience. Outposts solutions allow you to extend and run native AWS services on premises, and is available in a variety of form factors, from 1U and 2U Outposts servers to 42U Outposts racks, and multiple rack deployments.

With AWS Outposts, you can run some AWS services locally and connect to a broad range of services available in the local AWS Region. Run applications and workloads on premises using familiar AWS services, tools, and APIs. Outposts supports workloads and devices requiring low latency access to on-premises systems, local data processing, data residency, and application migration with local system interdependencies.

_AWS Outposts rack_ is a fully managed service that extends AWS infrastructure, services, APIs, and tools on premises for a truly consistent hybrid experience.

_AWS Outposts servers_ deliver compute and networking services for locations with space and capacity constraints.

### AWS Wavelength\*

_AWS Wavelength_ embeds AWS compute and storage services within 5G networks, providing mobile edge computing infrastructure for developing, deploying, and scaling ultra-low-latency applications.

## Containers:

_Container_ is a package for your code where you package up your application, its dependencies as well as any configurations that it needs to run. These containers run on top of EC2 instances and run in isolation from each other similar to how virtual machines work. But in this case, the host is an EC2 instance. When you use Docker containers on AWS, you need processes to start, stop, restart, and monitor containers running across not just one EC2 instance, but a number of them together which is called a cluster.

_Orchestration tools_ The process of doing these tasks is called container orchestration and it turns out it's really hard to do on your own. were created to help you manage your containers. ECS is designed to help you run your containerized applications at scale without the hassle of managing your own container orchestration software. EKS does a similar thing, but uses different tooling and with different features.

_If you are trying to host traditional applications_ and want full access to the underlying operating system like Linux or Windows, you are going to want to use EC2. If you are looking to host short running functions, service-oriented or event driven applications and you don't want to manage the underlying environment at all, look into the serverless AWS Lambda. If you are looking to run Docker container-based workloads on AWS, you first need to choose your orchestration tool. Do you want to use Amazon ECS or Amazon EKS? After you choose your tool, you then need to chose your platform. Do you want to run your containers on EC2 instances that you manage or in a serverless environment like AWS Fargate that is managed for you?

### Amazon Elastic Container Registry (Amazon ECR)\*

Amazon Elastic Container Registry (Amazon ECR) is a fully managed container registry offering high-performance hosting, so you can reliably deploy application images and artifacts anywhere.

### Amazon Elastic Container Service (Amazon ECS)

_Amazon Elastic Container Service (Amazon ECS)_ is a highly scalable, high-performance container management system that enables you to run and scale containerized applications on AWS.

Amazon ECS supports Docker containers. [Docker](https://www.docker.com/) is a software platform that enables you to build, test, and deploy applications quickly. AWS supports the use of open-source Docker Community Edition and subscription-based Docker Enterprise Edition. With Amazon ECS, you can use API calls to launch and stop Docker-enabled applications.

### Amazon Elastic Kubernetes Service (Amazon EKS)

_Amazon Elastic Kubernetes Service (Amazon EKS)_ is a fully managed service that you can use to run Kubernetes on AWS.

Kubernetes is open-source software that enables you to deploy and manage containerized applications at scale. A large community of volunteers maintains Kubernetes, and AWS actively works together with the Kubernetes community. As new features and functionalities release for Kubernetes applications, you can easily apply these updates to your applications managed by Amazon EKS.

## Customer Engagement:

### AWS Activate for Startups\*

Millions of customers, including thousands of the fastest-growing startups, use AWS to build fast, keep costs low, and prove what's possible.

### AWS IQ\*

Describe your needs, get responses from experts and consulting firms, and choose the expert(s) or consulting firm(s) with the skills and experience you need. Then agree to a proposal and payment type with the expert or consulting firm and a budget. For upfront or scheduled payments, you will agree to the payments when accepting the proposal. For milestone payments, your expert or consulting firm will send you payment requests as agreed to in the proposal, or when milestones are met. All payments and the associated charges will be charged to the payment method in your AWS bill.

### AWS Managed Services (AMS)\*

AWS Managed Services (AMS) helps you adopt AWS at scale and operate more efficiently and securely. We leverage standard AWS services and offer guidance and execution of operational best practices with specialized automations, skills, and experience that are contextual to your environment and applications. AMS provides proactive, preventative, and detective capabilities that raise the operational bar and help reduce risk without constraining agility, allowing you to focus on innovation.

### AWS Support\*

AWS Support is one-on-one, fast-response support from experienced technical support engineers. The service helps customers use AWS's products and features. With pay-by-the-month pricing and unlimited support cases, customers are freed from long-term commitments.

## Database:

### Amazon Aurora

_Amazon Aurora_is an enterprise-class relational database. It is compatible with MySQL and PostgreSQL relational databases. It is up to five times faster than standard MySQL databases and up to three times faster than standard PostgreSQL databases.

Amazon Aurora helps to reduce your database costs by reducing unnecessary input/output (I/O) operations, while ensuring that your database resources remain reliable and available.

Consider Amazon Aurora if your workloads require high availability. It replicates six copies of your data across three Availability Zones and continuously backs up your data to Amazon S3.

The other benefits are things like your data is replicated across facilities, so you have six copies at any given time. You can also deploy up to 15 read replicas, so you can offload your reads and scale performance. Additionally, there's continuous backups to S3, so you always have a backup ready to restore. You also get point in time recovery, so you can recover data from a specific period.

### Amazon DynamoDB

_Amazon DynamoDB_ is a key-value database service. It delivers single-digit millisecond performance at any scale.

**DynamoDB is serverless** , which means that you do not have to provision, patch, or manage servers. You also do not have to install, maintain, or operate software.

As the size of your database shrinks or grows, **DynamoDB automatically scales** to adjust for changes in capacity while maintaining consistent performance. This makes it a suitable choice for use cases that require high performance while scaling.

DynamoDB is a non-relational, NoSQL database. It is purpose built. Meaning it has specific use cases, and it isn't the best fit for every workload out there. It has millisecond response time. It's fully managed, and it's highly scalable.

_Amazon DynamoDB Accelerator (DAX)_ is an in-memory cache for DynamoDB. It helps improve response times from single-digit milliseconds to microseconds.

### Amazon MemoryDB for Redis\*

MemoryDB for Redis is a durable, in-memory database service that delivers ultra-fast performance. It is purpose-built for modern applications with microservices architectures.

MemoryDB is compatible with Redis, a popular open source data store, enabling you to quickly build applications using the same flexible and friendly Redis data structures, APIs, and commands that they already use today. With MemoryDB, all of your data is stored in memory, which enables you to achieve microsecond read and single-digit millisecond write latency and high throughput. MemoryDB also stores data durably across multiple Availability Zones (AZs) using a Multi-AZ transactional log to enable fast failover, database recovery, and node restarts.

### Amazon Neptune

_Amazon Neptune_ is a graph database service. You can use Amazon Neptune to build and run applications that work with highly connected datasets, such as recommendation engines, fraud detection, and knowledge graphs.

### Amazon RDS

_Amazon Relational Database Service (Amazon RDS)_ is a service that enables you to run relational databases in the AWS Cloud.

Amazon RDS is a managed service that automates tasks such as hardware provisioning, database setup, patching, and backups. With these capabilities, you can spend less time completing administrative tasks and more time using data to innovate your applications. You can integrate Amazon RDS with other services to fulfill your business and operational needs, such as using AWS Lambda to query your database from a serverless application.

Amazon RDS provides a number of different security options. Many Amazon RDS database engines offer encryption at rest (protecting data while it is stored) and encryption in transit (protecting data while it is being sent and received).

#### _Amazon RDS database engines_

Amazon RDS is available on six database engines, which optimize for memory, performance, or input/output (I/O). Supported database engines include:

1. Amazon Aurora
2. PostgreSQL
3. MySQL
4. MariaDB
5. Oracle Database
6. Microsoft SQL Server

## Developer Tools:

### AWS AppConfig\*

_AWS AppConfig_, a capability of AWS Systems Manager, to create, manage, and quickly deploy application configurations. A configuration is a collection of settings that influence the behavior of your application. You can use AWS AppConfig with applications hosted on Amazon Elastic Compute Cloud (Amazon EC2) instances, AWS Lambda, containers, mobile applications, or IoT devices. To view examples of the types of configurations you can manage by using AWS AppConfig, see Example configurations.

### AWS CLI\*

_AWS Command Line Interface (AWS CLI)_ is a unified tool to manage your AWS services. With just one tool to download and configure, you can control multiple AWS services from the command line and automate them through scripts.

The AWS CLI v2 offers several new features including improved installers, new configuration options such as AWS IAM Identity Center (successor to AWS SSO), and various interactive features.

### AWS Cloud9\*

_AWS Cloud9_ A cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser.

Comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, and PHP.

Quickly share your development environment with your team, enabling you to pair program and track each other's inputs in real time

### AWS CloudShell\*

_AWS CloudShell_, a browser-based shell, you can quickly run scripts with the AWS Command Line Interface (CLI), experiment with service APIs using the AWS CLI, and use other tools to increase your productivity. The CloudShell icon appears in AWS Regions where CloudShell is available.

### AWS CodeArtifact\*

_CodeArtifact_ allows you to store artifacts using popular package managers and build tools like Maven, Gradle, npm, Yarn, Twine, pip, and NuGet. CodeArtifact can automatically fetch software packages on demand from public package repositories so you can access the latest versions of application dependencies.

### AWS CodeBuild\*

_AWS CodeBuild_ is a fully managed continuous integration service in the cloud. CodeBuild compiles source code, runs tests, and produces packages that are ready to deploy. CodeBuild eliminates the need to provision, manage, and scale your own build servers. CodeBuild automatically scales up and down and processes multiple builds concurrently, so your builds don't have to wait in a queue. You can get started quickly by using CodeBuild prepackaged build environments, or you can use custom build environments to use your own build tools. With CodeBuild, you only pay by the minute.

### AWS CodeCommit\*

_AWS CodeCommit_ is a secure, highly scalable, fully managed source control service that hosts private Git repositories.

### AWS CodeDeploy\*

_CodeDeploy_ is a deployment service that automates application deployments to Amazon EC2 instances, on-premises instances, serverless Lambda functions, or Amazon ECS services.

### AWS CodePipeline\*

_AWS CodePipeline_ is a fully managed continuous delivery service that helps you automate your release pipelines for fast and reliable application and infrastructure updates.

### AWS CodeStar\*

_AWS CodeStar_ is a cloud‑based development service that provides the tools you need to quickly develop, build, and deploy applications on AWS. With AWS CodeStar, you can set up your entire continuous delivery toolchain in minutes, allowing you to start releasing code faster. AWS CodeStar makes it easy for your whole team to work together securely, with built-in role-based policies that allow you to easily manage access and add owners, contributors, and viewers to your projects. Each AWS CodeStar project comes with a unified project dashboard and integration with Atlassian JIRA software, a third-party issue tracking and project management tool. With the AWS CodeStar project dashboard, you can easily track your entire software development process, from a backlog work item to production code deployment.

### AWS X-Ray\*

AWS X-Ray provides a complete view of requests as they travel through your application and filters visual data across payloads, functions, traces, services, APIs, and more with no-code and low-code motions.

## End User Computing:

### Amazon AppStream 2.0\*

_AppStream 2.0_ is an AWS End User Computing (EUC) service that can be configured for SaaS application streaming or delivery of virtual desktops with selective persistence. When AppStream 2.0 is used for virtual desktops, saved files and application settings remain persistent between user sessions, and a fresh virtual desktop is assigned to the user every time they log on.

### Amazon WorkSpaces\*

_Amazon WorkSpaces_ is a fully managed desktop virtualization service for Windows, Linux, and Ubuntu, that allows you to access resources from any supported device.

### Amazon WorkSpaces Web\*

_Amazon WorkSpaces Web_ is a low cost, fully managed, Linux-based service, designed to facilitate secure browser access to internal websites and software-as-a-service (SaaS) applications from existing web browsers, without the administrative burden of appliances, managing infrastructure, specialized client software, or virtual private network (VPN) connections.

## Frontend Web and Mobile:

### AWS Amplify\*

_AWS Amplify_ is a complete solution that lets frontend web and mobile developers easily build, ship, and host full-stack applications on AWS, with the flexibility to leverage the breadth of AWS services as use cases evolve. No cloud expertise needed.

### AWS AppSync\*

_AWS AppSync_ A single data API: Simplify application development with GraphQL APIs by providing a single endpoint to securely query or update data from multiple databases, microservices, and APIs.

Built for real-time experiences: Easily create engaging real-time experiences with Pub/Sub APIs by automatically publishing data updates to subscribed API clients via serverless WebSockets connections.

100% serverless: Secure, monitor, log, and trace your APIs via built-in support for AWS WAF, CloudWatch and X-Ray. Fully managed setup, administration, auto-scaling, and high-availability.

### AWS Device Farm\*

_AWS Device Farm_ allows developers to increase application quality, time to market, and customer satisfaction by testing and interacting with real Android and iOS devices in the AWS Cloud. Developers can upload their app and test scripts and run automated tests in parallel across 100s of real devices, getting results, screenshots, video, and performance data in minutes. They can also debug and reproduce customer issues by swiping, gesturing, and interacting with a device through their web browser.

## Internet of Things (IoT):

### AWS IoT Core\*

_AWS IoT Core_ is a managed cloud platform that lets connected devices easily and securely interact with cloud applications and other devices. AWS IoT Core can support billions of devices and trillions of messages, and can process and route those messages to AWS endpoints and to other devices reliably and securely. With AWS IoT Core, your applications can keep track of and communicate with all your devices, all the time, even when they aren't connected.

### AWS IoT Greengrass\*

_AWS IoT Greengrass_ is an Internet of Things (IoT) open source edge runtime and cloud service that helps you build, deploy, and manage device software. Customers use AWS IoT Greengrass for their IoT applications on millions of devices in homes, factories, vehicles, and businesses. You can program your devices to act locally on the data they generate, execute predictions based on machine learning models, filter and aggregate device data, and only transmit necessary information to the cloud.

## Machine Learning:

### Amazon Comprehend\*

_Amazon Comprehend_ is a natural language processing (NLP) service that uses machine learning to find meaning and insights in text.

### Amazon Kendra\*

_Amazon Kendra_ Receive highly accurate answers with an easy-to-use enterprise search service powered by Machine Learning (ML).

Implement a unified search experience quickly across multiple structured and unstructured content repositories.

Use natural language processing (NLP) to get highly accurate answers without the need for machine learning (ML) expertise.

Fine-tune your search results based on content attributes, freshness, user behavior, and more.

### Amazon Lex\*

_Amazon Lex_ is a service for building conversational interfaces using voice and text. Powered by the same conversational engine as Alexa, Amazon Lex provides high quality speech recognition and language understanding capabilities, enabling addition of sophisticated, natural language 'chatbots' to new and existing applications. Amazon Lex reduces multi-platform development effort, allowing you to easily publish your speech or text chatbots to mobile devices and multiple chat services, like Facebook Messenger, Slack, Kik, or Twilio SMS. Native interoperability with AWS Lambda and Amazon CloudWatch and easy integration with many other services on the AWS platform including Amazon Cognito, and Amazon DynamoDB makes bot development effortless.

### Amazon Polly\*

_Amazon Polly_ uses deep learning technologies to synthesize natural-sounding human speech, so you can convert articles to speech. With dozens of lifelike voices across a broad set of languages, use Amazon Polly to build speech-activated applications.

### Amazon Rekognition\*

_Amazon Rekognition_ is a service that makes it easy to add powerful visual analysis to your applications. Rekognition Image lets you easily build powerful applications to search, verify, and organize millions of images. Rekognition Video lets you extract motion-based context from stored or live stream videos and helps you analyze them.

Rekognition Image is an image recognition service that detects objects, scenes, activities, landmarks, faces, dominant colors, and image quality. Rekognition Image also extracts text, recognizes celebrities, and identifies inappropriate content in images. It also allows you to search and compare faces.

### Amazon SageMaker\*

_Amazon SageMaker_ To make it easier to get started, Amazon SageMaker JumpStart provides a set of solutions for the most common use cases that can be deployed readily with just a few clicks.

Prepare, build, train, and deploy high-quality machine learning models quickly by bringing together a broad set of capabilities purpose-built for machine learning.

Amazon SageMaker is available for free, for 2 months, as part of the AWS Free Tier program. Users can get access to 250 hours per month of ml.t3.medium notebooks usage with the Free Tier.

### Amazon Textract\*

_Amazon Textract_ is a machine learning (ML) service that automatically extracts text, handwriting, and data from scanned documents. It goes beyond simple optical character recognition (OCR) to identify, understand, and extract data from forms and tables. Today, many companies manually extract data from scanned documents such as PDFs, images, tables, and forms, or through simple OCR software that requires manual configuration (which often must be updated when the form changes). To overcome these manual and expensive processes, Textract uses ML to read and process any type of document, accurately extracting text, handwriting, tables, and other data with no manual effort. You can quickly automate document processing and act on the information extracted, whether you're automating loans processing or extracting information from invoices and receipts. Textract can extract the data in minutes instead of hours or days. Additionally, you can add human reviews with Amazon Augmented AI to provide oversight of your models and check sensitive data.

Automatically extract printed text, handwriting, and data from any document.

### Amazon Transcribe\*

_Amazon Transcribe_ is an AWS Artificial Intelligence (AI) service that makes it easy for you to convert speech to text. Using Automatic Speech Recognition (ASR) technology, you can use Amazon Transcribe for a variety of business applications, including transcription of voice-based customer service calls, generation of subtitles on audio/video content, and conduct (text-based) content analysis on audio/video content.

Add speech to text capabilities to applications.

Recorded speech can be converted to text before it can be used in applications.

Uses a deep learning process called automatic speech recognition (ASR) to convert speech to text quickly and accurately.

### Amazon Translate\*

_Amazon Translate_ is a Neural Machine Translation (MT) service for translating text between supported languages. Powered by deep learning methods, the service provides high-quality, affordable, and customizable language translation, enabling developers to translate company and user-authored content, or build applications requiring support across multiple languages. The service can be used via an API, enabling either real-time or batch translation of text from the source language to the target language.

Neural machine translation service that delivers fast, high-quality, and affordable language translation.

Uses deep learning models to deliver more accurate and more natural sounding translation.

Localize content such as websites and applications for your diverse users.

## Management and Governance:

### AWS Auto Scaling\*

_AWS Auto Scaling_ monitors your applications and automatically adjusts capacity to maintain steady, predictable performance at the lowest possible cost. Using AWS Auto Scaling, it's easy to setup application scaling for multiple resources across multiple services in minutes.

### AWS CloudFormation

_AWS CloudFormation_ is an infrastructure as code tool that allows you to define a wide variety of AWS resources in a declarative way using JSON or YAML text-based documents called CloudFormation templates. A declarative format like this allows you to define what you want to build without specifying the details of exactly how to build it. CloudFormation lets you define what you want and the CloudFormation engine will worry about the details on calling APIs to get everything built out.

CloudFormation supports many different AWS resources from storage, databases, analytics, machine learning, and more. Once you define your resources in a CloudFormation template, CloudFormation will parse the template and begin provisioning all the resources you defined in parallel. CloudFormation manages all the calls to the backend AWS APIs for you. You can run the same CloudFormation template in multiple accounts or multiple regions, and it will create identical environments across them. There is less room for human error as it is a totally automated process.

### AWS CloudTrail

_AWS CloudTrail_ records API calls for your account. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, and more. You can think of CloudTrail as a "trail" of breadcrumbs (or a log of actions) that someone has left behind them.

Recall that you can use API calls to provision, manage, and configure your AWS resources. With CloudTrail, you can view a complete history of user activity and API calls for your applications and resources.

Events are typically updated in CloudTrail within 15 minutes after an API call. You can filter events by specifying the time and date that an API call occurred, the user who requested the action, the type of resource that was involved in the API call, and more.

AWS CloudTrail, the comprehensive API auditing tool. The engine is simple, every request made to AWS, it doesn't matter if it's to launch an EC2 instance, or add a row to a DynamoDB table, or change a user's permissions. Every request gets logged in the CloudTrail engine. The engine records exactly who made the request, which operator, when did they send the API call? Where were they? What was their IP address? And what was the response? Did something change? And what is the new state? Was the request denied?

From an auditing perspective, well, this is fabulous. So imagine that you're dealing with an auditor who is checking to make sure that nobody from the outside can access your database. That's a good thing. Well, okay, you build a security group that locks out external traffic. But remember that a root-level administrator still has permissions to change those settings, right?

Well, so how do you prove to the auditor that the security group settings never changed? The answer is CloudTrail. And then CloudTrail can save those logs indefinitely in secure S3 buckets. In addition, with tamper-proof methods like Vault Lock, you then can show absolute provenance of all of these critical security audit logs.

#### CloudTrail Insights

Within CloudTrail, you can also enable CloudTrail Insights(opens in a new tab). This optional feature allows CloudTrail to automatically detect unusual API activities in your AWS account.

For example, CloudTrail Insights might detect that a higher number of Amazon EC2 instances than usual have recently launched in your account. You can then review the full event details to determine which actions you need to take next.

### Amazon CloudWatch

_Amazon CloudWatch_ is a web service that enables you to monitor and manage various metrics and configure alarm actions based on data from those metrics.

CloudWatch uses metrics to represent the data points for your resources. AWS services send metrics to CloudWatch. CloudWatch then uses these metrics to create graphs automatically that show how performance has changed over time.

CloudWatch allows you to monitor your AWS infrastructure and the applications you run on AWS in real time. It works by tracking and monitoring metrics. Think of metrics as variables that are tied to your resources

#### _CloudWatch alarms_

With CloudWatch, you can create alarms(opens in a new tab) that automatically perform actions if the value of your metric has gone above or below a predefined threshold.

For example, suppose that your company's developers use Amazon EC2 instances for application development or testing purposes. If the developers occasionally forget to stop the instances, the instances will continue to run and incur charges.

In this scenario, you could create a CloudWatch alarm that automatically stops an Amazon EC2 instance when the CPU utilization percentage has remained below a certain threshold for a specified period. When configuring the alarm, you can specify to receive a notification whenever this alarm is triggered.

CloudWatch alarms are integrated with SNS. So we can then send an SMS to the manager to say, clean the machine. You can create all sorts of custom alarms for metrics from all different types of AWS resources.

The _CloudWatch dashboard_ feature enables you to access all the metrics for your resources from a single location. For example, you can use a CloudWatch dashboard to monitor the CPU utilization of an Amazon EC2 instance, the total number of requests made to an Amazon S3 bucket, and more. You can even customize separate dashboards for different business purposes, applications, or resources.

#### _CloudWatch benefits_

1. You can have access to all your _metrics from a central location_. This enables you to collect metrics and logs from all your AWS resources applications, and services that run on AWS and on-premises servers, helping you break down silos so that you can easily gain system-wide visibility.
2. You can also get _visibility across your applications_, infrastructure, and services, which means you gain insights across your distributed stack so you can correlate and visualize metrics and logs to quickly pinpoint and resolve issues. This in turn means you can reduce mean time to resolution, or MTTR, and improve total cost of ownership, or TCO.
3. This means _freeing up important resources_ like developers to focus on adding business value. you can drive insights to optimize applications and operational resources. By, for example, aggregating usage across an entire fleet of EC2 instances to derive operational and utilization insights.

### AWS Compute Optimizer\*

_AWS Compute Optimizer_ is a service that analyzes the configuration and utilization metrics of your AWS resources. It reports whether your resources are optimal, and generates optimization recommendations to reduce the cost and improve the performance of your workloads. Compute Optimizer also provides graphs showing recent utilization metric history data, as well as projected utilization for recommendations, which you can use to evaluate which recommendation provides the best price-performance trade-off. The analysis and visualization of your usage patterns can help you decide when to move or resize your running resources, and still meet your performance and capacity requirements.

### AWS Config\*

_AWS Config_ is a fully managed service that provides you with resource inventory, configuration history, and configuration change notifications to use security and governance. With AWS Config, you can discover existing AWS resources, record configurations for third-party resources, export a complete inventory of your resources with all configuration details, and determine how a resource was configured at any point in time. These capabilities use compliance auditing, security analysis, resource change tracking, and troubleshooting.

### AWS Control Tower\*

_AWS Control Tower_ offers a straightforward way to set up and govern an AWS multi-account environment, following prescriptive best practices. AWS Control Tower orchestrates the capabilities of several other AWS services, including AWS Organizations, AWS Service Catalog, and AWS IAM Identity Center (successor to AWS Single Sign-On), to build a landing zone in less than an hour. Resources are set up and managed on your behalf.

AWS Control Tower orchestration extends the capabilities of AWS Organizations. To help keep your organizations and accounts from drift, which is divergence from best practices, AWS Control Tower applies controls (sometimes called guardrails). For example, you can use controls to help ensure that security logs and necessary cross-account access permissions are created, and not altered.

### AWS Health Dashboard\*

_AWS Health Dashboard_ is the single place to learn about the availability and operations of AWS services. You can view the overall status of AWS services, and you can sign in to view personalized communications about your particular AWS account or organization. Your account view provides deeper visibility into resource issues, upcoming changes, and important notifications.

### AWS Launch Wizard\*

_AWS Launch Wizard_ is a console-based service to quickly and easily size, configure, and deploy third-party applications on AWS without the need to identify and provision individual AWS resources.

### AWS License Manager\*

_License Manager_ provides you with the flexibility and control to manage license usage to match your organizational structure and processes. License Manager can be set in different configurations to address specific business needs.

### AWS Management Console

_The AWS Management Console_ is browser-based interface. Through the console, you can manage your AWS resources visually and in a way that is easy to digest. This is great for getting started and building your knowledge of the services. It's also useful for building out test environments or viewing AWS bills, viewing monitoring, and working with other non-technical resources. You can quickly access recently used services and search for other services by name, keyword, or acronym. The console includes wizards and automated workflows that can simplify the process of completing tasks.
 You can also use the AWS Console mobile application to perform tasks such as monitoring resources, viewing alarms, and accessing billing information. Multiple identities can stay logged into the AWS Console mobile app at the same time.

### AWS Organizations

Suppose that your company has multiple AWS accounts. You can use  **AWS Organizations****  **to consolidate and manage multiple AWS accounts within a central location.

When you create an organization, AWS Organizations automatically creates a  **root** , which is the parent container for all the accounts in your organization.

In AWS Organizations, you can centrally control permissions for the accounts in your organization by using **service control policies (SCPs)**.

#### service control policies (SCPs)

SCPs enable you to place restrictions on the AWS services, resources, and individual API actions that users and roles in each account can access.

#### Organizational units (OU)

In AWS Organizations, you can group accounts into organizational units (OUs) to make it easier to manage accounts with similar business or security requirements. When you apply a policy to an OU, all the accounts in the OU automatically inherit the permissions specified in the policy.

By organizing separate accounts into OUs, you can more easily isolate workloads or applications that have specific security requirements. For instance, if your company has accounts that can access only the AWS services that meet certain regulatory requirements, you can put these accounts into one OU. Then, you can attach a policy to the OU that blocks access to all other AWS services that do not meet the regulatory requirements.

_Consolidated Billing_. At the end of every month, instead of having to pay an AWS bill for every single account, you can roll those bills up into one bill owned by the owner of the organization. This makes it easier to keep track of your bills. You don't get 100 bills, if you have 100 AWS accounts.

You can still view your AWS bill in an itemized fashion. So you know which accounts spent what, but it all goes into one central location for ease of viewing. There are other benefits of using this feature too. One of them is that the usage for AWS resources is rolled up to the organization level. AWS does offer bulk pricing. Each individual account may only have a small amount of usage, but you can get the bulk discount pricing because of the aggregate across all accounts in the organization. In addition, if you have a savings plan in place, or if you are using reserved instances for EC2, it can be shared across AWS accounts in the organization. The best part about this is that the feature is free and easy to use. So it simplifies the billing process, lets you share savings across accounts and doesn't cost you any extra money.

### AWS Resource Groups and Tag Editor\*

_Resource Groups_ to organize your AWS resources. AWS Resource Groups is the service that lets you manage and automate tasks on large numbers of resources at one time.

_Tags_ are key and value pairs that act as metadata for organizing your AWS resources. With most AWS resources, you have the option of adding tags when you create the resource. Examples of resources include an Amazon Elastic Compute Cloud (Amazon EC2) instance, an Amazon Simple Storage Service (Amazon S3) bucket, or a secret in AWS Secrets Manager.

### AWS Service Catalog\*

_AWS Service Catalog_ lets you centrally manage your cloud resources to achieve governance at scale of your infrastructure as code (IaC) templates, written in CloudFormation or Terraform configurations. With AWS Service Catalog, you can meet your compliance requirements while making sure your customers can quickly deploy the cloud resources they need.

### AWS Systems Manager\*

_AWS Systems Manager_ allows you to safely automate common and repetitive IT operations and management tasks. With Systems Manager Automation, you use predefined playbooks, or you can build, run, and share wiki-style automated playbooks to enable AWS resource management across multiple accounts and AWS Regions.

### AWS Trusted Advisor

_AWS Trusted Advisor_ is a web service that inspects your AWS environment and provides real-time recommendations in accordance with AWS best practices.

Trusted Advisor compares its findings to AWS best practices in five categories: cost optimization, performance, security, fault tolerance, and service limits. For the checks in each category, Trusted Advisor offers a list of recommended actions and additional resources to learn more about AWS best practices.

The guidance provided by AWS Trusted Advisor can benefit your company at all stages of deployment. For example, you can use AWS Trusted Advisor to assist you while you are creating new workflows and developing new applications. You can also use it while you are making ongoing improvements to existing applications and resources.

#### _AWS Trusted Advisor dashboard_

When you access the Trusted Advisor dashboard on the AWS Management Console, you can review completed checks for cost optimization, performance, security, fault tolerance, and service limits.

For each category:

- The green check indicates the number of items for which it detected no problems.
- The orange triangle represents the number of recommended investigations.
- The red circle represents the number of recommended actions.

#### _Trusted Advisor 5 Pillars:_

1.
#### _Cost Optimization_

Trusted Advisor can help you save cost with actionable recommendations by analyzing usage, configuration and spend. Examples include identifying idle RDS DB instances, underutilized EBS volumes, unassociated Elastic IP addresses, and excessive timeouts in Lambda functions.

1.
#### _Performance_

Trusted Advisor can help improve the performance of your services with actionable recommendations by analyzing usage and configuration. Examples include analyzing EBS throughput and latency, compute usage of EC2 instances, and configurations on CloudFront.

1.
#### _Security_

Trusted Advisor can help improve the security of your AWS environment by suggesting foundational security best practices curated by security experts. Examples include identifying RDS security group access risk, exposed access keys, and unnecessary S3 bucket permissions.

1.
#### _Fault Tolerance_

Trusted Advisor can help improve the reliability of your services. Examples include examining Auto scaling EC2 groups, deleted health checks on Route 53, disabled Availability Zones, and disabled RDS backups.

1.
#### _Service Limits (quotas)_

Service quotas are the maximum number of resources that you can create in an AWS account. AWS implements quotas to provide highly available and reliable service to all customers, and protects you from unintentional spend. Trusted Advisor will notify you once you reach more than 80% of a service quota. You can then follow recommendations to delete resources or request a quota increase.

### AWS Well-Architected Tool

The AWS Well-Architected Tool lets you review your workloads against current AWS best practices and obtain advice on how to architect your workloads for the cloud. This tool uses the AWS Well-Architected Framework.

It kind of looks like a traffic light system, with green being go, keep up the good work. Orange being, you should probably look into this because there's room for improvement. And red being, okay, you should look at this because something is at risk. These are areas where the tool has detected potential issues, and it presents you with a plan on how to architect using established best practices. It should be noted that you can always override these settings if the questions don't apply to your scenario. It's very customizable.

### AWS OpsWorks

AWS OpsWorks is a configuration management service that provides managed instances of Chef and Puppet. Chef and Puppet are automation platforms that allow you to use code to automate the configurations of your servers. OpsWorks lets you use Chef and Puppet to automate how servers are configured, deployed, and managed across your Amazon EC2 instances or on-premises compute environments.

## Migration and Transfer:

### AWS Application Discovery Service\*

_AWS Application Discovery Service_ collects and presents data to enable enterprise customers to understand the configuration, usage, and behavior of servers in their IT environments. Server data is retained in the Application Discovery Service where it can be tagged and grouped into applications to help organize AWS migration planning. Collected data can be exported for analysis in Excel or other cloud migration analysis tools.

### AWS Application Migration Service\*

_AWS Application Migration Service_ minimizes time-intensive, error-prone manual processes by automating the conversion of your source servers to run natively on AWS. It also simplifies application modernization with built-in and custom optimization options.

### AWS Database Migration Service (AWS DMS)

_AWS Database Migration Service (AWS DMS)_ enables you to migrate relational databases, nonrelational databases, and other types of data stores.

With AWS DMS, you move data between a source database and a target database. The source and target databases can be of the same type or different types. During the migration, your source database remains operational, reducing downtime for any applications that rely on the database.

For example, suppose that you have a MySQL database that is stored on premises in an Amazon EC2 instance or in Amazon RDS. Consider the MySQL database to be your source database. Using AWS DMS, you could migrate your data to a target database, such as an Amazon Aurora database.

_Use Cases_

1. _Development and test migration_ Enabling developers to test applications against production data without affecting production users
2. _Database consolidation_is when you have several databases and want to consolidate them into one central database.
3. _Continuous Replication_is when you use DMS to perform continuous data replication. This could be for disaster recovery or because of geographic separation.

### AWS Migration Hub\*

_AWS Migration Hub_ provides access to the tools you need to collect and inventory your existing IT assets based on actual usage, analyze application components and infrastructure dependencies, and group resources into applications. You can generate migration strategy and Amazon Elastic Compute Cloud (EC2) instance recommendations for business case and migration planning, track the progress of application migrations to AWS, and modernize applications already running on AWS.

### AWS Schema Conversion Tool (AWS SCT)\*

_AWS Schema Conversion Tool (AWS SCT)_ to convert your existing database schema from one database engine to another. You can convert relational OLTP schema, or data warehouse schema.

### AWS Snow Family

It should be noted that all Snow Family devices are designed to be secure and tamper-resistant while on-site or in transit. This means the hardware and software is cryptographically signed, and all data stored is automatically encrypted using 256-bit encryption keys, owned and managed by you, the customer. You can even use AWS Key Management Service to generate and manage keys.

_AWS Snowcone_ and it's a device that holds up to eight terabytes of data and contains edge computing. Edge computing options are Amazon EC2 instances and AWS IoT Greengrass. To obtain one, you place an order via AWS Management Console we ship it to you, you plug it in and copy your data, and finally, ship it back to us. We'll then copy the data to your AWS account, usually an Amazon S3 bucket that you own and your data is available to use. Customers usually use these devices to ship terabytes of information such as analytics data, video libraries, image collections, backups, and even tape replacement data.

AWS Snowcone is a small, rugged, and secure edge computing and data transfer device. It features 2 CPUs, 4 GB of memory, and up to 14 TB of usable storage.

_Snowball Edge_. It comes in two versions: a Snowball Edge Compute Optimized option and a Snowball Edge Storage Optimized option. Even better is that they fit into existing server racks and can be clustered for greater computing needs. Ones you plug them into your infrastructure, you can even run AWS Lambda functions, Amazon EC2-compatible AMI's, or even AWS IoT Greengrass to perform simple processing of data right then and there. Customers usually ship these to remote locations, where it's trickier to have a lot of computing power lying around. The use cases include capturing of streams from IoT devices, image compression, video transcoding, and even industrial signaling.

#### AWS Snowball offers two types of devices:

_Snowball Edge Storage Optimized_ devices are well suited for large-scale data migrations and recurring transfer workflows, in addition to local computing with higher capacity needs.

- Storage: 80 TB of hard disk drive (HDD) capacity for block volumes and Amazon S3 compatible object storage, and 1 TB of SATA solid state drive (SSD) for block volumes.
- Compute: 40 vCPUs, and 80 GiB of memory to support Amazon EC2 sbe1 instances (equivalent to C5).

_Snowball Edge Compute Optimized_ provides powerful computing resources for use cases such as machine learning, full motion video analysis, analytics, and local computing stacks.

- Storage: 80-TB usable HDD capacity for Amazon S3 compatible object storage or Amazon EBS compatible block volumes and 28 TB of usable NVMe SSD capacity for Amazon EBS compatible block volumes.
- Compute: 104 vCPUs, 416 GiB of memory, and an optional NVIDIA Tesla V100 GPU. Devices run Amazon EC2 sbe-c and sbe-g instances, which are equivalent to C5, M5a, G3, and P3 instances.

_AWS Snowmobile_, and as the name suggests, it's housed in a 45-foot rugged shipping container and pulled along by a freaking truck, I mean this thing is huge. It houses 100 petabytes and is ideal for the largest migrations and even data center shutdowns. We drive the truck to your designated location, plug it in, and it then appears as a network attached storage device with, like I said, capacity of up to 100 petabytes. It is tamper resistant, waterproof, temperature controlled, it even has fire suppression and GPS tracking. I mean, can you believe that it also has 24/7 video surveillance with a dedicated security team and escort security vehicle during transit? That's some serious business.

AWS Snowmobile is an exabyte-scale data transfer service used to move large amounts of data to AWS.

- You can transfer up to 100 petabytes of data per Snowmobile, a 45-foot long ruggedized shipping container, pulled by a semi trailer truck.

### AWS Transfer Family\*

#### _AWS Transfer Family_ Managed File Transfer (MFT)

The AWS Transfer Family offers fully managed support for the transfer of files over SFTP, AS2, FTPS, and FTP directly into and out of Amazon S3 or Amazon EFS. You can seamlessly migrate, automate, and monitor your file transfer workflows by maintaining existing client-side configurations for authentication, access, and firewalls — so nothing changes for your customers, partners, and internal teams, or their applications.

_SFTP stands for Secure Shell (SSH) File Transfer Protocol_, a network protocol used for secure transfer of data over the internet. The protocol supports the full security and authentication functionality of SSH, and is widely used to exchange data between business partners in a variety of industries including financial services, healthcare, media and entertainment, retail, advertising, and more.

_FTP stands for File Transfer Protocol_, a network protocol used for the transfer of data. FTP uses a separate channel for control and data transfers. The control channel is open until terminated or inactivity timeout, the data channel is active for the duration of the transfer. FTP uses cleartext and does not support encryption of traffic.

_FTPS stands for File Transfer Protocol over SSL_, and is an extension to FTP. Like FTP, FTPS uses a separate channel for control and data transfers. The control channel is open until terminated or inactivity timeout, while the data channel is active for the duration of the transfer. FTPS uses Transport Layer Security (TLS) to encrypt traffic, and allows encryption of both the control and data channel connections either concurrently or independently.

## Networking and Content Delivery:

### Amazon API Gateway\*

_Amazon API Gateway_ is a fully managed service that makes it easy for developers to publish, maintain, monitor, and secure APIs at any scale. With a few clicks in the AWS Management Console, you can create an API that acts as a "front door" for applications to access data, business logic, or functionality from your back-end services, such as applications running on Amazon Elastic Compute Cloud (Amazon EC2), Amazon Elastic Container Service (Amazon ECS) or AWS Elastic Beanstalk, code running on AWS Lambda, or any web application. Amazon API Gateway handles all of the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including traffic management, authorization and access control, monitoring, and API version management. Amazon API Gateway has no minimum fees or startup costs. For HTTP APIs and REST APIs, you pay only for the API calls you receive and the amount of data transferred out. For WebSocket APIs, you pay only for messages sent and received and for the time a user/device is connected to the WebSocket API.

### Amazon CloudFront

_Amazon CloudFront_ is a service that helps deliver data, video, applications, and APIs to customers around the world with low latency and high transfer speeds. Amazon CloudFront uses what are called Edge locations, all around the world, to help accelerate communication with users, no matter where they are.

Amazon CloudFront is a content delivery network (CDN) that allows you to store (cache) your content at "edge locations" located around the world.

This allows customers to access content more quickly and provides security against DDoS attacks.

CloudFront can be used for data, videos, applications, and APIs.

#### CloudFront benefits:

1. Cache content at Edge Location for fast distribution to customers.
2. Built-in Distributed Denial of Service (DDoS) attack protection.
3. Integrates with many AWS services (S3, EC2, ELB, Route 53, Lambda).

#### Origins and Distributions:

1. An origin is the origin of the files that the CDN will distribute.
2. Origins can be either an S3 bucket, an EC2 instance, an Elastic Load Balancer, or Route 53 – can also be external (non-AWS).
3. To distribute content with CloudFront you need to create a distribution.

#### CloudFront uses Edge Locations and Regional Edge Caches:

1. An edge location is the location where content is cached (separate to AWS regions/AZs).
2. Requests are automatically routed to the nearest edge location.
3. Regional Edge Caches are located between origin web servers and global edge locations and have a larger cache.
4. Regional Edge caches aim to get content closer to users.

### AWS Direct Connect

_AWS Direct Connect_. Direct Connect allows you to establish a completely private, dedicated fiber connection from your data center to AWS. You work with a Direct Connect partner in your area to establish this connection, because like my magic doorway, AWS Direct Connect provides a physical line that connects your network to your AWS VPC. This can help you meet high regulatory and compliance needs, as well as sidestep any potential bandwidth issues.

[**AWS Direct Connect**](https://aws.amazon.com/directconnect/) is a service that lets you to establish a dedicated private connection between your data center and a VPC.

### AWS Global Accelerator\*

_AWS Global Accelerator_ is a networking service that helps you improve the availability, performance, and security of your public applications. Global Accelerator provides two global static public IPs that act as a fixed entry point to your application endpoints, such as Application Load Balancers, Network Load Balancers, Amazon Elastic Compute Cloud (EC2) instances, and elastic IPs.

### Amazon Route 53

_Amazon Route 53_ is AWS's domain name service, or DNS, and it's highly available and scalable. But wait, what is DNS, you say? Think of DNS as a translation service. But instead of translating between languages, it translates website names into IP, or Internet Protocol, addresses that computers can read.

Route 53 can direct traffic to different endpoints using several different routing policies, such as latency-based routing, geolocation DNS, geoproximity, and weighted round robin. If we take geolocation DNS, that means we direct traffic based on where the customer is located.

You can even use Route 53 to register domain names, so you can buy and manage your own domain names right on AWS.

Amazon Route 53 is a DNS web service. It gives developers and businesses a reliable way to route end users to internet applications hosted in AWS.

Amazon Route 53 connects user requests to infrastructure running in AWS (such as Amazon EC2 instances and load balancers). It can route users to infrastructure outside of AWS.

Another feature of Route 53 is the ability to manage the DNS records for domain names. You can register new domain names directly in Route 53. You can also transfer DNS records for existing domain names managed by other domain registrars. This enables you to manage all of your domain names within a single location.

#### Route 53 performs three main functions:

_Domain registration_ – Route 53 allows you to register domain names.

_Domain Name Service (DNS)_ – Route 53 translates name to IP addresses using a global network of authoritative DNS servers.

_Health checking – Route 53_ sends automated requests to your application to verify that it's reachable, available, and functional.

#### Policy What it Does

_Simple_ - Simple DNS response providing the IP address associated with a name

_Failover_ - If primary is down (based on health checks), routes to secondary destination

_Geolocation_ - Uses geographic location you're in (e.g. Europe) to route you to the closest region

_Geoproximity_ - Routes you to the closest region within a geographic area

_Latency_ - Directs you based on the lowest latency route to resources

_Multivalue answer_ - Returns several IP addresses and functions as a basic load balancer

_Weighted_ - Uses the relative weights assigned to resources to determine which to route to

### Amazon VPC

_Amazon VPC_ enables you to provision an isolated section of the AWS Cloud. In this isolated section, you can launch resources in a virtual network that you define. Within a virtual private cloud (VPC), you can organize your resources into subnets. A  **subnet**  is a section of a VPC that can contain resources such as Amazon EC2 instances.

You place resources into different subnets. Subnets are chunks of IP addresses in your VPC that allow you to group resources together. Subnets, along with networking rules control whether resources are either publicly or privately available.

In a VPC, subnets can communicate with each other. For example, you might have an application that involves Amazon EC2 instances in a public subnet communicating with databases that are located in a private subnet.

_Internet gateway (igw)_ An internet gateway is a connection between a VPC and the internet. You can think of an internet gateway as being similar to a doorway that customers use to enter the coffee shop. Without an internet gateway, no one can access the resources within your VPC.

_Virtual private gateway_To access private resources in a VPC, you can use a  **virtual private gateway.** A virtual private gateway enables you to establish a virtual private network (VPN) connection between your VPC and a private network, such as an on-premises data center or internal corporate network. A virtual private gateway allows traffic into the VPC only if it is coming from an approved network.

### AWS VPN\*

AWS VPN is comprised of two services: AWS Site-to-Site VPN and AWS Client VPN. AWS Site-to-Site VPN enables you to securely connect your on-premises network or branch office site to your Amazon Virtual Private Cloud (Amazon VPC). AWS Client VPN enables you to securely connect users to AWS or on-premises networks

#### _AWS Client VPN_

_AWS Client VPN_ is a fully managed, elastic VPN service that automatically scales up or down based on user demand. Because it is a cloud VPN solution, you don't need to install and manage hardware or software-based solutions, or try to estimate how many remote users to support at one time.

#### AWS Site-to-Site VPN

_AWS Site-to-Site VPN_ creates a secure connection between your data center or branch office and your AWS cloud resources. For globally distributed applications, the accelerated Site-to-Site VPN option provides even greater performance by working with AWS Global Accelerator.

## Security, Identity, and Compliance:

### AWS Artifact

_AWS Artifact_ is a service that provides on-demand access to AWS security and compliance reports and select online agreements. AWS Artifact consists of two main sections: AWS Artifact Agreements and AWS Artifact Reports.

Depending on your company's industry, you may need to uphold specific standards. An audit or inspection will ensure that the company has met those standards.

AWS Artifact provides access to AWS security and compliance documents, such as AWS ISO certifications, Payment Card Industry (PCI) reports, and Service Organization Control (SOC) reports

#### AWS Artifact Agreements

Suppose that your company needs to sign an agreement with AWS regarding your use of certain types of information throughout AWS services. You can do this through AWS Artifact Agreements.

In AWS Artifact Agreements, you can review, accept, and manage agreements for an individual account and for all your accounts in AWS Organizations. Different types of agreements are offered to address the needs of customers who are subject to specific regulations, such as the Health Insurance Portability and Accountability Act (HIPAA).

#### AWS Artifact Reports

Next, suppose that a member of your company's development team is building an application and needs more information about their responsibility for complying with certain regulatory standards. You can advise them to access this information in AWS Artifact Reports.

AWS Artifact Reports provide compliance reports from third-party auditors. These auditors have tested and verified that AWS is compliant with a variety of global, regional, and industry-specific security standards and regulations. AWS Artifact Reports remains up to date with the latest reports released. You can provide the AWS audit artifacts to your auditors or regulators as evidence of AWS security controls.

Customer Compliance Center

The Customer Compliance Center contains resources to help you learn more about AWS compliance. In the Customer Compliance Center, you can read customer compliance stories to discover how companies in regulated industries have solved various compliance, governance, and audit challenges.

You can also access compliance whitepapers and documentation on topics such as:

- AWS answers to key compliance questions
- An overview of AWS risk and compliance
- An auditing security checklist

Additionally, the Customer Compliance Center includes an auditor learning path. This learning path is designed for individuals in auditing, compliance, and legal roles who want to learn more about how their internal operations can demonstrate compliance using the AWS Cloud.

### AWS Audit Manager\*

_AWS Audit Manager_ to map your compliance requirements to AWS usage data with prebuilt and custom frameworks and automated evidence collection.

### AWS Certificate Manager (ACM)\*

_AWS Certificate Manager (ACM_) to provision, manage, and deploy public and private SSL/TLS certificates for use with AWS services and your internal connected resources. ACM removes the time-consuming manual process of purchasing, uploading, and renewing SSL/TLS certificates.

### AWS CloudHSM\*

_AWS CloudHSM_ service helps you meet corporate, contractual, and regulatory compliance requirements for data security by using dedicated Hardware Security Module (HSM) instances within the AWS cloud. AWS and AWS Marketplace partners offer a variety of solutions for protecting sensitive data within the AWS platform, but for some applications and data subject to contractual or regulatory mandates for managing cryptographic keys, additional protection may be necessary. CloudHSM complements existing data protection solutions and allows you to protect your encryption keys within HSMs that are designed and validated to government standards for secure key management. CloudHSM allows you to securely generate, store, and manage cryptographic keys used for data encryption in a way that keys are accessible only by you.

### Amazon Cognito\*

_Amazon Cognito_ Deliver frictionless customer identity and access management (CIAM) with a cost-effective and customizable platform.

Add security features that support various compliance regulations, such as adaptive authentication, support compliance, and data residency requirements.

Scale to millions of users across devices with a fully managed, high-performant, and reliable identity store.

### Amazon Detective\*

_Amazon Detective_ simplifies the investigative process and helps security teams conduct faster and more effective investigations. With the Amazon Detective prebuilt data aggregations, summaries, and context, you can quickly analyze and determine the nature and extent of possible security issues

### AWS Directory Service\*

_AWS Directory Service_ for Microsoft Active Directory, also known as AWS Managed Microsoft AD, activates your directory-aware workloads and AWS resources to use managed AD on AWS

### AWS Firewall Manager\*

_AWS Firewall Manager_ is a security management service that allows you to centrally configure and manage firewall rules across your accounts and applications in AWS Organizations. As new applications are created, Firewall Manager makes it easier to bring new applications and resources into compliance by enforcing a common set of security rules.

### Amazon GuardDuty

_Amazon GuardDuty_ is a service that provides intelligent threat detection for your AWS infrastructure and resources. It identifies threats by continuously monitoring the network activity and account behavior within your AWS environment.

After you have enabled GuardDuty for your AWS account, GuardDuty begins monitoring your network and account activity. You do not have to deploy or manage any additional security software. GuardDuty then continuously analyzes data from multiple AWS sources, including VPC Flow Logs and DNS logs.

If GuardDuty detects any threats, you can review detailed findings about them from the AWS Management Console. Findings include recommended steps for remediation. You can also configure AWS Lambda functions to take remediation steps automatically in response to GuardDuty's security findings.

### AWS Identity and Access Management (IAM)

_AWS Identity and Access Management (IAM)_ enables you to manage access to AWS services and resources securely.

IAM gives you the flexibility to configure access based on your company's specific operational and security needs. You do this by using a combination of IAM features:

- IAM users, groups, and roles
- IAM policies
- Multi-factor authentication

#### _AWS account Root User_

When you first create an AWS account, you begin with an identity known as the  **root user** (opens in a new tab).

The root user is accessed by signing in with the email address and password that you used to create your AWS account. You can think of the root user as being similar to the owner of the coffee shop. It has complete access to all the AWS services and resources in the account.

#### _Root User Best practice:_

Do  **not**  use the root user for everyday tasks. Instead, use the root user to create your first IAM user and assign it permissions to create other users. Then, continue to create other IAM users, and access those identities for performing regular tasks throughout AWS. Only use the root user when you need to perform a limited number of tasks that are only available to the root user. Examples of these tasks include changing your root user email address and changing your AWS support plan.

_IAM users_

_IAM user_ is an identity that you create in AWS. It represents the person or application that interacts with AWS services and resources. It consists of a name and credentials.

By default, when you create a new IAM user in AWS, it has no permissions associated with it. To allow the IAM user to perform specific actions in AWS, such as launching an Amazon EC2 instance or creating an Amazon S3 bucket, you must grant the IAM user the necessary permissions.

#### _IAM User_ _Best practice:_

We recommend that you create individual IAM users for each person who needs to access AWS.

Even if you have multiple employees who require the same level of access, you should create individual IAM users for each of them. This provides additional security by allowing each IAM user to have a unique set of security credentials.

#### _IAM policies_

_IAM policy_ is a document that allows or denies permissions to AWS services and resources.

IAM policies enable you to customize users' levels of access to resources. For example, you can allow users to access all of the Amazon S3 buckets within your AWS account, or only a specific bucket.

#### _IAM policies Best practice:_

Follow the security principle of  **least privilege**  when granting permissions. By following this principle, you help to prevent users or roles from having more permissions than needed to perform their tasks.

For example, if an employee needs access to only a specific bucket, specify the bucket in the IAM policy. Do this instead of granting the employee access to all of the buckets in your AWS account.

#### _IAM groups_

_IAM group_ is a collection of IAM users. When you assign an IAM policy to a group, all users in the group are granted permissions specified by the policy.

Here's an example of how this might work in the coffee shop. Instead of assigning permissions to cashiers one at a time, the owner can create a "Cashiers" IAM group. The owner can then add IAM users to the group and then attach permissions at the group level.

Assigning IAM policies at the group level also makes it easier to adjust permissions when an employee transfers to a different job. For example, if a cashier becomes an inventory specialist, the coffee shop owner removes them from the "Cashiers" IAM group and adds them into the "Inventory Specialists" IAM group. This ensures that employees have only the permissions that are required for their current role.

#### IAM Roles

In the coffee shop, an employee rotates to different workstations throughout the day. Depending on the staffing of the coffee shop, this employee might perform several duties: work at the cash register, update the inventory system, process online orders, and so on.

When the employee needs to switch to a different task, they give up their access to one workstation and gain access to the next workstation. The employee can easily switch between workstations, but at any given point in time, they can have access to only a single workstation. This same concept exists in AWS with IAM roles.

An IAM role is an identity that you can assume to gain temporary access to permissions.

#### IAM Roles Best practice:

IAM roles are ideal for situations in which access to services or resources needs to be granted temporarily, instead of long-term.

#### Multi-factor authentication

Have you ever signed in to a website that required you to provide multiple pieces of information to verify your identity? You might have needed to provide your password and then a second form of authentication, such as a random code sent to your phone. This is an example of  **multi-factor authentication**.

In IAM, multi-factor authentication (MFA) provides an extra layer of security for your AWS account.

### AWS IAM Identity Center (Successor AWS Single Sign-On)\*

_AWS IAM Identity Center_ helps you securely create or connect your workforce identities and manage their access centrally across AWS accounts and applications. IAM Identity Center is the recommended approach for workforce authentication and authorization on AWS for organizations of any size and type. Using IAM Identity Center, you can create and manage user identities in AWS, or connect your existing identity source, including Microsoft Active Directory, Okta, Ping Identity, JumpCloud, Google Workspace, and Azure Active Directory (Azure AD).

### Amazon Inspector

Amazon Inspector helps to improve the security and compliance of applications by running automated security assessments. It checks applications for security vulnerabilities and deviations from security best practices, such as open access to Amazon EC2 instances and installations of vulnerable software versions.

After Amazon Inspector has performed an assessment, it provides you with a list of security findings. The list prioritizes by severity level, including a detailed description of each security issue and a recommendation for how to fix it. However, AWS does not guarantee that following the provided recommendations resolves every potential security issue. Under the shared responsibility model, customers are responsible for the security of their applications, processes, and tools that run on AWS services.

### AWS Key Management Service (AWS KMS)

In the same way, you must ensure that your applications' data is secure while in storage **(encryption at rest)** and while it is transmitted, known as  **encryption in transit**.

_AWS Key Management Service (AWS KMS)_ enables you to perform encryption operations through the use of cryptographic keys. A cryptographic key is a random string of digits used for locking (encrypting) and unlocking (decrypting) data. You can use AWS KMS to create, manage, and use cryptographic keys. You can also control the use of keys across a wide range of services and in your applications.

With AWS KMS, you can choose the specific levels of access control that you need for your keys. For example, you can specify which IAM users and roles are able to manage keys. Alternatively, you can temporarily disable keys so that they are no longer in use by anyone. Your keys never leave AWS KMS, and you are always in control of them.

### Amazon Macie\*

_Amazon Macie_ is a data security service that discovers sensitive data using machine learning and pattern matching, provides visibility into data security risks, and enables automated protection against those risks.

### AWS Network Firewall\*

_AWS Network Firewall_, you can define firewall rules that provide fine-grained control over network traffic. Network Firewall works together with AWS Firewall Manager so you can build policies based on Network Firewall rules and then centrally apply those policies across your virtual private clouds (VPCs) and accounts.

### AWS Resource Access Manager (AWS RAM)\*

_AWS Resource Access Manager (AWS RAM)_ helps you securely share your resources across AWS accounts, within your organization or organizational units (OUs) in AWS Organizations, and with IAM roles and IAM users for supported resource types. You can use AWS RAM to share resources with other AWS accounts. This eliminates the need to provision and manage resources in every account. When you share a resource with another account, that account is granted access to the resource and any policies and permissions in that account apply to the shared resource.

### AWS Secrets Manager\*

_AWS Secrets Manager_ helps you manage, retrieve, and rotate database credentials, application credentials, OAuth tokens, API keys, and other secrets throughout their lifecycles. Many AWS services that use secrets store them in Secrets Manager.

Secrets Manager helps you improve your security posture, because you no longer need hard-coded credentials in application source code. Storing the credentials in Secrets Manager helps avoid possible compromise by anyone who can inspect your application or the components. You replace hard-coded credentials with a runtime call to the Secrets Manager service to retrieve credentials dynamically when you need them.

### AWS Security Hub\*

_AWS Security Hub_ provides you with a comprehensive view of your security state in AWS and helps you assess your AWS environment against security industry standards and best practices.

Security Hub collects security data across AWS accounts, AWS services, and supported third-party products and helps you analyze your security trends and identify the highest priority security issues.

Security Hub offers automation features that help you triage and remediate security issues.

### AWS Shield

_AWS Shield_ is a service that protects applications against DDoS attacks. AWS Shield provides two levels of protection: Standard and Advanced.

#### _AWS Shield Standard_

AWS Shield Standard automatically protects all AWS customers at no cost. It protects your AWS resources from the most common, frequently occurring types of DDoS attacks.

As network traffic comes into your applications, AWS Shield Standard uses a variety of analysis techniques to detect malicious traffic in real time and automatically mitigates it.

#### _AWS Shield Advanced_

AWS Shield Advanced is a paid service that provides detailed attack diagnostics and the ability to detect and mitigate sophisticated DDoS attacks.

It also integrates with other services such as Amazon CloudFront, Amazon Route 53, and Elastic Load Balancing. Additionally, you can integrate AWS Shield with AWS WAF by writing custom rules to mitigate complex DDoS attacks.

### AWS WAF

_AWS WAF_ is a web application firewall that lets you monitor network requests that come into your web applications. AWS WAF works together with Amazon CloudFront and an Application Load Balancer. Recall the network access control lists that you learned about in an earlier module. AWS WAF works in a similar way to block or allow traffic. However, it does this by using a web access control list (ACL) to protect your AWS resources.

Here's an example of how you can use AWS WAF to allow and block specific requests.

Suppose that your application has been receiving malicious network requests from several IP addresses. You want to prevent these requests from continuing to access your application, but you also want to ensure that legitimate users can still access it. You configure the web ACL to allow all requests except those from the IP addresses that you have specified. When a request comes into AWS WAF, it checks against the list of rules that you have configured in the web ACL. If a request does not come from one of the blocked IP addresses, it allows access to the application. However, if a request comes from one of the blocked IP addresses that you have specified in the web ACL, AWS WAF denies access.

## Serverless:

_Serverless means_ that you cannot actually see or access the underlying infrastructure or instances that are hosting your application. Instead, all the management of the underlying environment from a provisioning, scaling, high availability, and maintenance perspective are taken care of for you. All you need to do is focus on your application and the rest is taken care of.

Another _benefit of serverless_ computing is the flexibility to scale serverless applications automatically. Serverless computing can adjust the applications' capacity by modifying the units of consumptions, such as throughput and memory.

### AWS Fargate

_AWS Fargate_ is a serverless compute engine for containers. It works with both Amazon ECS and Amazon EKS.

When using AWS Fargate, you do not need to provision or manage servers. AWS Fargate manages your server infrastructure for you. You can focus more on innovating and developing your applications, and you pay only for the resources that are required to run your containers.

### AWS Lambda

AWS Lambda is a service that lets you run code without needing to provision or manage servers.

While using AWS Lambda, you pay only for the compute time that you consume. Charges apply only when your code is running. You can also run code for virtually any type of application or backend service, all with zero administration.

AWS Lambda is one serverless compute option. Lambda's a service that allows you to upload your code into what's called a Lambda function. Configure a trigger and from there, the service waits for the trigger. When the trigger is detected, the code is automatically run in a managed environment, an environment you do not need to worry too much about because it is automatically scalable, highly available and all of the maintenance in the environment itself is done by AWS. Lambda will scale your function to meet demand. Lambda is designed to run code under 15 minutes so this isn't for long running processes like deep learning. It's more suited for quick processing like a web backend, handling requests or a backend expense report processing service where each invocation takes less than 15 minutes to complete.

## Storage:

### AWS Backup\*

_AWS Backup_ is a fully managed service that centralizes and automates data protection across AWS services and hybrid workloads. It provides core data protection features, ransomware recovery capabilities, and compliance insights and analytics for data protection policies and operations.

### Amazon Elastic Block Store (Amazon EBS)

_Amazon Elastic Block Store_is a service that provides block-level storage volumes that you can use with Amazon EC2 instances. If you stop or terminate an Amazon EC2 instance, all the data on the attached EBS volume remains available.

To create an EBS volume, you define the configuration (such as volume size and type) and provision it. After you create an EBS volume, it can attach to an Amazon EC2 instance.

Because EBS volumes are for data that needs to persist, it's important to back up the data. You can take incremental backups of EBS volumes by creating Amazon EBS snapshots.

#### _Amazon EBS snapshots_

_EBS snapshot_ is an incremental backup. This means that the first backup taken of a volume copies all the data. For subsequent backups, only the blocks of data that have changed since the most recent snapshot are saved.

Incremental backups are different from full backups, in which all the data in a storage volume copies each time a backup occurs. The full backup includes data that has not changed since the most recent backup.

### Amazon Elastic File System (Amazon EFS)

_Amazon Elastic File System (Amazon EFS)_ is a scalable file system used with AWS Cloud services and on-premises resources. As you add and remove files, Amazon EFS grows and shrinks automatically. It can scale on demand to petabytes without disrupting applications.

### AWS Elastic Disaster Recovery\*

_AWS Elastic Disaster Recovery_ automatically converts your servers to boot and run natively on AWS when you launch instances for drills or recovery.

### Amazon FSx\*

_Amazon FSx_ for Windows File Server? Amazon FSx for Windows File Server provides fully managed Microsoft Windows file servers, backed by a fully native Windows file system. FSx for Windows File Server has the features, performance, and compatibility to easily lift and shift enterprise applications to the AWS Cloud.

### Amazon S3

_Amazon Simple Storage Service (Amazon S3_**)** is a service that provides object-level storage. Amazon S3 stores data as objects in buckets.

You can upload any type of file to Amazon S3, such as images, videos, text files, and so on. For example, you might use Amazon S3 to store backup files, media files for a website, or archived documents. Amazon S3 offers unlimited storage space. The maximum file size for an object in Amazon S3 is 5 TB.

When you upload a file to Amazon S3, you can set permissions to control visibility and access to it. You can also use the Amazon S3 versioning feature to track changes to your objects over time.

In _object storage_, each object consists of data, metadata, and a key.

The data might be an image, video, text document, or any other type of file. Metadata contains information about what the data is, how it is used, the object size, and so on. An object's key is its unique identifier.

In _file storage_, multiple clients (such as users, applications, servers, and so on) can access data that is stored in shared file folders. In this approach, a storage server uses block storage with a local file system to organize files. Clients access data through file paths.

Compared to block storage and object storage, file storage is ideal for use cases in which a large number of services and resources need to access the same data at the same time.

- Object sharing – the ability to make any object publicly available via a URL.
- Lifecycle management – set rules to transfer objects between storage classes at defined time intervals.
- Versioning – automatically keep multiple versions of an object (when enabled).
- Encryption can be enabled for bucket.
- Data is secured using ACLs and bucket policies.

#### S3 Charges:

- Storage.
- Requests.
- Storage management pricing.
- Data transfer pricing.
- Transfer acceleration.

_Typical use cases include:_

- _Backup and Storage_ – Provide data backup and storage services for others.
- _Application Hosting_ – Provide services that deploy, install, and manage web applications.
- _Media Hosting_ – Build a redundant, scalable, and highly available infrastructure that hosts video, photo, or music uploads and downloads.
- _Software Delivery_ – Host your software applications that customers can download.
- _Static Website_ – you can configure a static website to run from an S3 bucket.

_Amazon S3 storage classes_

With Amazon S3, you pay only for what you use. You can choose from a range of storage classes to select a fit for your business and cost needs. When selecting an Amazon S3 storage class, consider these two factors:

- How often you plan to retrieve your data
- How available you need your data to be

1. S3 Standard

- Designed for frequently accessed data
- Stores data in a minimum of three Availability Zones

Amazon S3 Standard provides high availability for objects. This makes it a good choice for a wide range of use cases, such as websites, content distribution, and data analytics. Amazon S3 Standard has a higher cost than other storage classes intended for infrequently accessed data and archival storage.

The first storage class is called S3 Standard and comes with 11 nines of durability. That means an object stored in S3 Standard has a 99.999999999 percent – that's a lot of nines – probability that it will remain intact after a period of 1 year.

1. _S3 Standard-Infrequent Access (S3 Standard-IA)_

- Ideal for infrequently accessed data
- Similar to Amazon S3 Standard but has a lower storage price and higher retrieval price

Amazon S3 Standard-IA is ideal for data infrequently accessed but requires high availability when needed. Both Amazon S3 Standard and Amazon S3 Standard-IA store data in a minimum of three Availability Zones. Amazon S3 Standard-IA provides the same level of availability as Amazon S3 Standard but with a lower storage price and a higher retrieval price.

1. _S3 One Zone-Infrequent Access (S3 One Zone-IA)_

- Stores data in a single Availability Zone
- Has a lower storage price than Amazon S3 Standard-IA

Compared to S3 Standard and S3 Standard-IA, which store data in a minimum of three Availability Zones, S3 One Zone-IA stores data in a single Availability Zone. This makes it a good storage class to consider if the following conditions apply:

- You want to save costs on storage.
- You can easily reproduce your data in the event of an Availability Zone failure.

1. _S3 Intelligent-Tiering_

- Ideal for data with unknown or changing access patterns
- Requires a small monthly monitoring and automation fee per object

In the S3 Intelligent-Tiering storage class, Amazon S3 monitors objects' access patterns. If you haven't accessed an object for 30 consecutive days, Amazon S3 automatically moves it to the infrequent access tier, S3 Standard-IA. If you access an object in the infrequent access tier, Amazon S3 automatically moves it to the frequent access tier, S3 Standard.

1. _S3 Glacier Instant Retrieval_

- Works well for archived data that requires immediate access
- Can retrieve objects within a few milliseconds

When you decide between the options for archival storage, consider how quickly you must retrieve the archived objects. You can retrieve objects stored in the S3 Glacier Instant Retrieval storage class within milliseconds, with the same performance as S3 Standard.

1. _S3 Glacier Flexible Retrieval_

- Low-cost storage designed for data archiving
- Able to retrieve objects within a few minutes to hours

S3 Glacier Flexible Retrieval is a low-cost storage class that is ideal for data archiving. For example, you might use this storage class to store archived customer records or older photos and video files. You can retrieve your data from S3 Glacier Flexible Retrieval from 1 minute to 12 hours.

1. _S3 Glacier Deep Archive_

- Lowest-cost object storage class ideal for archiving
- Able to retrieve objects within 12 hours

S3 Deep Archive supports long-term retention and digital preservation for data that might be accessed once or twice in a year. This storage class is the lowest-cost storage in the AWS Cloud, with data retrieval from 12 to 48 hours. All objects from this storage class are replicated and stored across at least three geographically dispersed Availability Zones.

1. _S3 Outposts_

- Creates S3 buckets on Amazon S3 Outposts
- Makes it easier to retrieve, store, and access data on AWS Outposts

Amazon S3 Outposts delivers object storage to your on-premises AWS Outposts environment. Amazon S3 Outposts is designed to store data durably and redundantly across multiple devices and servers on your Outposts. It works well for workloads with local data residency requirements that must satisfy demanding performance needs by keeping data close to on-premises applications.

### AWS Storage Gateway\*

_AWS Storage Gateway_ is a hybrid cloud storage service that gives you on-premises access to virtually unlimited cloud storage. Storage Gateway provides a standard set of storage protocols such as iSCSI, SMB, and NFS, which allow you to use AWS storage without rewriting your existing applications.

## AWS Global Infrastructure:

### Regions & Availability Zones:

Each Region is made up of multiple data centers. AWS calls a single data center or a group of data centers, an Availability Zone or AZ. Each Availability Zone is one or more discrete data centers with redundant power, networking, and connectivity. When you launch an Amazon EC2 instance, it launches a virtual machine on a physical hardware that is installed in an Availability Zone. This means each AWS Region consists of multiple isolated and physically separate Availability Zones within a geographic Region. as a best practice with AWS, we always recommend you run across at least two Availability Zones in a Region. This means redundantly deploying your infrastructure in two different AZs.

#### Some key points about Regions.

1. Regions are geographically isolated areas, where you can access services needed to run your enterprise.
2. Regions contain Availability Zones, that allow you to run across physically separated buildings, tens of miles of separation, while keeping your application logically unified. Availability Zones help you solve high availability and disaster recovery scenarios, without any additional effort on your part.
3. AWS Edge locations run Amazon CloudFront to help get content closer to your customers, no matter where they are in the world.

### Selecting a Region

When determining the right Region for your services, data, and applications, consider the following four business factors:

1.
#### Compliance with data governance and legal requirements

Depending on your company and location, you might need to run your data out of specific areas. For example, if your company requires all of its data to reside within the boundaries of the UK, you would choose the London Region.

Not all companies have location-specific data regulations, so you might need to focus more on the other three factors.

1.
#### Proximity to your customers

Selecting a Region that is close to your customers will help you to get content to them faster.

1.
#### Available services within a Region

Sometimes, the closest Region might not have all the features that you want to offer to customers.

1.
#### Pricing

Suppose that you are considering running applications in both the United States and Brazil. The way Brazil's tax structure is set up, it might cost 50% more to run the same workload out of the São Paulo Region compared to the Oregon Region

### Availability Zones

An Availability Zone is a single data center or a group of data centers within a Region. Availability Zones are located tens of miles apart from each other. This is close enough to have low latency (the time between when content requested and received) between Availability Zones. However, if a disaster occurs in one part of the Region, they are distant enough to reduce the chance that multiple Availability Zones are affected.

### Edge Locations

An edge location is a site that Amazon CloudFront uses to store cached copies of your content closer to your customers for faster delivery.

Edge locations are separate from Regions, so you can push content from inside a Region to a collection of Edge locations around the world, in order to accelerate communication and content delivery. AWS Edge locations, also run more than just CloudFront. They run a domain name service, or DNS, known as Amazon Route 53, helping direct customers to the correct web locations with reliably low latency.

## Interacting with AWS Services:

In AWS, everything is an API call. An API is an application programming interface. And what that means is, there are pre-determined ways for you to interact with AWS services. And you can invoke or call these APIs to provision, configure, and manage your AWS resources.

_The AWS Management Console_ is browser-based interface. Through the console, you can manage your AWS resources visually and in a way that is easy to digest. This is great for getting started and building your knowledge of the services. It's also useful for building out test environments or viewing AWS bills, viewing monitoring, and working with other non-technical resources. You can quickly access recently used services and search for other services by name, keyword, or acronym. The console includes wizards and automated workflows that can simplify the process of completing tasks.
 You can also use the AWS Console mobile application to perform tasks such as monitoring resources, viewing alarms, and accessing billing information. Multiple identities can stay logged into the AWS Console mobile app at the same time.

_The AWS Command Line Interface or CLI_. The CLI allows you to make API calls using the terminal on your machine. This is different than the visual navigation style of the Management Console. Writing commands using the CLI makes actions scriptable and repeatable. So, you can write and run your commands to launch an EC2 Instance. And if you want to launch another, you can just run the pre-written command again. This makes it less susceptible to human error. And you can have these scripts run automatically, like on a schedule, or triggered by another process. AWS CLI enables you to control multiple AWS services directly from the command line within one tool. AWS CLI is available for users on Windows, macOS, and Linux.

_The AWS Software Development Kits or SDKs_. The SDKs allow you to interact with AWS resources through various programming languages. This makes it easy for developers to create programs that use AWS without using the low level APIs, as well as avoiding that manual resource creation that we just talked about.

## Summaries

### What is Cloud Computing:

The on-demand delivery of IT resources over the internet with pay-as-you-go pricing.

This means that you can make requests for IT resources like compute, networking, storage, analytics, or other types of resources, and then they're made available for you on demand. You don't pay for the resource upfront. Instead, you just provision and pay at the end of the month.

### Cloud Computing Models

There are 3 common types of cloud computing model

1. Infrastructure as a service (IaaS).
2. Platform as a service (PaaS).
3. Software as a service (SaaS).

#### Infrastructure as a Service (IaaS)

Infrastructure as a Service (IaaS) contains the basic building blocks for cloud IT and typically provide access to networking features, computers (virtual or on dedicated hardware), and data storage space.

IaaS provides you with the highest level of flexibility and management control over your IT resources and is very similar to the existing IT resources that many IT departments and developers are familiar with today.

#### Platform as a Service (PaaS)

Platform as a Service (PaaS) removes the need for your organization to manage the underlying infrastructure (usually hardware and operating systems) and allows you to focus on the deployment and management of your applications.

This helps you be more efficient as you don't need to worry about resource procurement, capacity planning, software maintenance, patching, or any of the other undifferentiated heavy lifting involved in running your application.

#### Software as a Service (SaaS)

Software as a Service (SaaS) provides you with a completed product that is run and managed by the service provider. In most cases, people referring to Software as a Service are referring to end-user applications.

With a SaaS offering you do not have to think about how the service is maintained or how the underlying infrastructure is managed; you only need to think about how you will use that piece of software.

A common example of a SaaS application is web-based email which you can use to send and receive email without having to manage feature additions to the email product or maintain the servers and operating systems that the email program is running on.

SaaS provides high availability, fault tolerance, scalability an elasticity.

### Advantages of cloud computing

Operating in the AWS Cloud offers many benefits over computing in on-premises or hybrid environments.

#### six advantages of cloud computing:

- Trade upfront expense for variable expense.
- Benefit from massive economies of scale.
- Stop guessing capacity.
- Increase speed and agility.
- Stop spending money running and maintaining data centers.
- Go global in minutes.

1.
#### Trade upfront expense for variable expense.

Upfront expenses include data centers, physical servers, and other resources that you would need to invest in before using computing resources.

Instead of investing heavily in data centers and servers before you know how you're going to use them, you can pay only when you consume computing resources.

1.
#### Benefit from massive economies of scale.

By using cloud computing, you can achieve a lower variable cost than you can get on your own. Because usage from hundreds of thousands of customers aggregates in the cloud, providers such as AWS can achieve higher economies of scale. Economies of scale translate into lower pay-as-you-go prices.

1.
#### Stop guessing capacity.

With cloud computing, you don't have to predict how much infrastructure capacity you will need before deploying an application.

For example, you can launch Amazon Elastic Compute Cloud (Amazon EC2) instances when needed and pay only for the compute time you use. Instead of paying for resources that are unused or dealing with limited capacity, you can access only the capacity that you need, and scale in or out in response to demand.

1.
#### Increase speed and agility.

The flexibility of cloud computing makes it easier for you to develop and deploy applications. This flexibility also provides your development teams with more time to experiment and innovate.

1.
#### Stop spending money running and maintaining data centers.

Cloud computing in data centers often requires you to spend more money and time managing infrastructure and servers. A benefit of cloud computing is the ability to focus less on these tasks and more on your applications and customers.

1.
#### Go global in minutes.

The AWS Cloud global footprint enables you to quickly deploy applications to customers around the world, while providing them with low latency.

Types of Cloud Deployment

#### 3 common types of cloud deployment:

1. _Public Cloud_ – e.g. AWS, Microsoft Azure, Google Cloud Platform (GCP).
2. _Hybrid Cloud_ – a mixture of public and private clouds.
3. _Private Cloud (on-premises)_ – a cloud managed in your own data center, e.g. Hyper-V, OpenStack, VMware.

#### Public Cloud

A cloud-based application is fully deployed in the cloud and all parts of the application run in the cloud. Applications in the cloud have either been created in the cloud or have been migrated from an existing infrastructure to take advantage of the benefits of cloud computing.

Cloud-based applications can be built on low-level infrastructure pieces or can use higher level services that provide abstraction from the management, architecting, and scaling requirements of core infrastructure.

#### Hybrid

A hybrid deployment is a way to connect infrastructure and applications between cloud-based resources and existing resources that are not located in the cloud.

The most common method of hybrid deployment is between the cloud and existing on-premises infrastructure to extend, and grow, an organization's infrastructure into the cloud while connecting cloud resources to the internal system.

#### On-premises

The deployment of resources on-premises, using virtualization and resource management tools, is sometimes called the "private cloud."

On-premises deployment doesn't provide many of the benefits of cloud computing but is sometimes sought for its ability to provide dedicated resources.

In most cases this deployment model is the same as legacy IT infrastructure while using application management and virtualization technologies to try and increase resource utilization.

### Compute in the cloud:

EC2, you can dynamically spin up and spin down virtual servers called EC2 instances. When you launch an EC2 instance, you choose the instance family. The instance family determines the hardware the instance runs on.

And you can have instances that are built for your specific purpose. The categories are general purpose, compute optimized, memory optimized, accelerated computing, and storage optimized.

You can scale your EC2 instances either vertically by resizing the instance, or horizontally by launching new instances and adding them to the pool. You can set up automated horizontal scaling, using Amazon EC2 Auto Scaling.

Once you've scaled your EC2 instances out horizontally, you need something to distribute the incoming traffic across those instances. This is where the Elastic Load Balancer comes into play.

EC2 instances have different pricing models. There is On-Demand, which is the most flexible and has no contract, spot pricing, which allows you to utilize unused capacity at a discounted rate, Savings Plans or Reserved Instances, which allow you to enter into a contract with AWS to get a discounted rate when you commit to a certain level of usage, and Savings Plans which apply to AWS Lambda, and AWS Fargate, as well as EC2 instances.

We also covered messaging services. There is Amazon Simple Queue Service or SQS. This service allows you to decouple system components. Messages remain in the queue until they are either consumed or deleted. Amazon Simple Notification Service or SNS, is used for sending messages like emails, text messages, push notifications, or even HTTP requests. Once a message is published, it is sent to all of these subscribers.

You also learned that AWS has different types of compute services beyond just virtual servers like EC2. There are container services like Amazon Elastic Container Service, or ECS. And there's Amazon Elastic Kubernetes Service, or EKS. Both of which are container orchestration tools. You can use these tools with EC2 instances, but if you don't want to manage that, you don't need to.

You can use AWS Fargate, which allows you to run your containers on top of a serverless compute platform. Then there is AWS Lambda, which allows you to just upload your code, and configure it to run based on triggers. And you only get charged for when the code is actually running. No containers, no virtual machines. Just code and configuration.

### AWS Global Infrastructure:

Logical clusters of data centers make up Availability Zones, Availability Zones in turn make up Regions, and those are spread globally. You then choose what Regions and Availability Zones you want to operate out of and as a best practice, you should always deploy infrastructure across at least two Availability Zones. And some AWS services like Elastic Load Balancing, Amazon SQS, and Amazon SNS already do this for you.

Edge locations and how you can deploy content there to speed up delivery to your customers. We even touched upon edge devices like AWS Outposts which allow you to run AWS infrastructure right in your own data center.

how to provision AWS resources through various options, such as the AWS Management Console, the SDK, CLI, AWS Elastic Beanstalk, and AWS CloudFormation, where you learned how you can set up your infrastructure as code.

### Networking:

#### Network Hardening

AWS has a wide range of tools that cover every layer of security: network hardening, application security, user identity, authentication and authorization, distributed denial-of-service or DDoS prevention, data integrity, encryption.

The public subnets have access to the internet gateway; the private subnets do not.

But subnets can also control traffic permissions. Packets are messages from the internet, and every packet that crosses the subnet boundaries gets checked against something called a network access control list or network ACL. This check is to see if the packet has permissions to either leave or enter the subnet based on who it was sent from and how it's trying to communicate.

_network ACLs_

A network ACL is a virtual firewall that controls inbound and outbound traffic at the subnet level. Network ACLs perform  **stateless**  packet filtering. They remember nothing and check packets that cross the subnet border each way: inbound and outbound. When a packet response for that request comes back to the subnet, the network ACL does not remember your previous request. The network ACL checks the packet response against its list of rules to determine whether to allow or deny. After a packet has entered a subnet, it must have its permissions evaluated for resources within the subnet, such as Amazon EC2 instances.

You can think of **network ACLs** as passport control officers. If you're on the approved list, you get through. If you're not on the list, or if you're explicitly on the do-not-enter list, then you get blocked. Network ACLs check traffic going into and leaving a subnet, just like passport control. The list gets checked on your way into a country and on the way out. And just because you were let in doesn't necessarily mean they're gonna let you out. Approved traffic can be sent on its way, and potentially harmful traffic, like attempts to gain control of a system through administrative requests, they get blocked before they ever touch the target. You can't hack what you can't touch.

Now, this sounds like great security, but it doesn't answer all of the network control issues. Because a network ACL only gets to evaluate a packet if it crosses a subnet boundary, in or out. It doesn't evaluate if a packet can reach a specific EC2 instance or not. Sometimes, you'll have multiple EC2 instances in the same subnet, but they might have different rules around who can send them messages, what port those messages are allowed to be sent to. So, you need instance level network security as well.

By default, your account's default network ACL allows all inbound and outbound traffic, but you can modify it by adding your own rules. For custom network ACLs, all inbound and outbound traffic is denied until you add rules to specify which traffic should be allowed. Additionally, all network ACLs have an explicit deny rule. This rule ensures that if a packet doesn't match any of the other rules on the list, the packet is denied.

_security groups_

A security group is a virtual firewall that controls inbound and outbound traffic for an Amazon EC2 instance. By default, a security group denies all inbound traffic and allows all outbound traffic. You can add custom rules to configure which traffic should be allowed; any other traffic would then be denied. Security groups perform  **stateful**  packet filtering. They remember previous decisions made for incoming packets. When a packet response for that request returns to the instance, the security group remembers your previous request. The security group allows the response to proceed, regardless of inbound security group rules.

To solve instance level access questions, we introduce **security groups**. Every EC2 instance, when it's launched, automatically comes with a security group. And by default, the security group does not allow any traffic into the instance at all. All ports are blocked; all IP addresses sending packets are blocked. That's very secure, but perhaps not very useful. If you want an instance to actually accept traffic from the outside, like say, a message from a front end instance or a message from the Internet. So obviously, you can modify the security group to accept a specific type of traffic. In the case of a website, you want web-based traffic or HTTPS to be accepted but not other types of traffic, say an operating system or administration requests.

#### Security Group and a Network ACL Key Differences:

The key difference between a security group and a network ACL is the security group is stateful, meaning, as we talked about, it has some kind of a memory when it comes to who to allow in or out, and the network ACL is stateless, which remembers nothing and checks every single packet that crosses its border regardless of any circumstances. With both network ACLs and security groups, you can configure custom rules for the traffic in your VPC. As you continue to learn more about AWS security and networking, make sure to understand the differences between network ACLs and security groups.

#### Subnets

A subnet is a section of a VPC in which you can group resources based on security or operational needs. Subnets can be public or private.

_Public subnets_ contain resources that need to be accessible by the public, such as an online store's website.

_Private subnets_ contain resources that should be accessible only through your private network, such as a database that contains customers' personal information and order histories. In a VPC, subnets can communicate with each other. For example, you might have an application that involves Amazon EC2 instances in a public subnet communicating with databases that are located in a private subnet.

#### Domain Name System (DNS)

Suppose that AnyCompany has a website hosted in the AWS Cloud. Customers enter the web address into their browser, and they are able to access the website. This happens because of _Domain Name System (DNS_**)** resolution. DNS resolution involves a customer DNS resolver communicating with a company DNS server.

You can think of DNS as being the phone book of the internet. DNS resolution is the process of translating a domain name to an IP address.

1. When you enter the domain name into your browser, this request is sent to a customer DNS resolver.
2. The customer DNS resolver asks the company DNS server for the IP address that corresponds to AnyCompany's website.
3. The company DNS server responds by providing the IP address for AnyCompany's website, 192.0.2.0.

### Storage and Databases:

### Storage

The first one we learned about is Elastic Block Store volumes, and you attach those to EC2 instances so you have local storage that is not ephemeral.

You learned about how S3 and how you can store objects in AWS with the click of a button or call of an API.

#### Amazon S3 and Amazon EBS Key Differences:

#### S3

In the regional object storage corner, weighing in at unlimited storage, with individual objects at 5,000 gigabytes in size, they specialize in write once/read many, they are 99 .999 999 999% durable, they are Amazon Simple Storage Service!

#### EBS

In the block storage corner, weighing in at sizes up to 16 tebibytes each, with a unique ability to survive the termination of their Amazon EC2 instances, they are solid state, they are spinning platters, they are Amazon Elastic Block Storage!

#### Use Cases

Let's say you're running a photo analysis website where users upload a photo of themselves, and your application finds the animals that look just like them. You have potentially millions of animal pictures that all need to be indexed and possibly viewed by thousands of people at once. This is the perfect use case for S3. S3 is already web enabled. Every object already has a URL that you can control access rights to who can see or manage the image. It's regionally distributed, which means that it has 11 nines of durability, so no need to worry about backup strategies. S3 is your backup strategy. Plus the cost savings is substantial overrunning the same storage load on EBS. With the additional advantage of being serverless, no Amazon EC2 instances are needed. **Sounds like S3 is the judge's winner here for this round.**

You have an 80-gigabyte video file that you're making edit corrections on. To know the best storage class here, we need to understand the difference between object storage and block storage. Object storage treats any file as a complete, discreet object. Now this is great for documents, and images, and video files that get uploaded and consumed as entire objects, but every time there's a change to the object, you must re-upload the entire file. There are no delta updates. Block storage breaks those files down to small component parts or blocks. This means, for that 80-gigabyte file, when you make an edit to one scene in the film and save that change, the engine only updates the blocks where those bits live. If you're making a bunch of micro edits, using EBS, elastic block storage, is the perfect use case. If you were using S3, every time you saved the changes, the system would have to upload all 80 gigabytes, the whole thing, every time. **EBS clearly wins round two.**

This means, if you are using complete objects or only occasional changes, S3 is victorious. If you are doing complex read, write, change functions, then, absolutely, EBS is your knockout winner. Your winner depends on your individual workload. Each service is the right service for specific needs. Once you understand what you need, you will know which service is your champion!

#### Amazon EBS and Amazon EFS Key Differences:

Amazon EBS volumes attach to EC2 instances and are an Availability Zone-level resource. In order to attach EC2 to EBS, you need to be in the same AZ. You can save files on it. You can also run a database on top of it. Or store applications on it. It's a hard drive. If you provision a two terabyte EBS volume and fill it up, it doesn't automatically scale to give you more storage. So that's EBS.

#### EBS Vs EFS

Amazon EFS can have multiple instances reading and writing from it at the same time.

But it isn't just a blank hard drive that you can write to. It is a true file system for Linux. It is also a regional resource. Meaning any EC2 instance in the Region can write to the EFS file system. As you write more data to EFS, it automatically scales. No need to provision any more volumes.

#### Amazon EBS

An Amazon EBS volume stores data in a  **single**  Availability Zone.

To attach an Amazon EC2 instance to an EBS volume, both the Amazon EC2 instance and the EBS volume must reside within the same Availability Zone.

#### Amazon EFS

Amazon EFS is a regional service. It stores data in and across  **multiple**  Availability Zones.

The duplicate storage enables you to access data concurrently from all the Availability Zones in the Region where a file system is located. Additionally, on-premises servers can access Amazon EFS using AWS Direct Connect.

### Databases

The various relational database options available on AWS. Or for the workloads that just need a key-value pair, we have the non-relational offering called DynamoDB.

Next up was EFS for file storage use cases.

We then have Amazon Redshift for all our data warehouse needs.

And to aid in migration of existing databases, we have DMS or Database Migration Service

#### Relational databases

In a _relational database_, data is stored in a way that relates it to other pieces of data.

An example of a relational database might be the coffee shop's inventory management system. Each record in the database would include data for a single item, such as product name, size, price, and so on.

Relational databases use structured query language (SQL) to store and query data. This approach allows data to be stored in an easily understandable, consistent, and scalable way. For example, the coffee shop owners can write a SQL query to identify all the customers whose most frequently purchased drink is a medium latte.

_Lift-and-Shift_ and migrate your database to run on Amazon EC2. This means you have control over the same variables you do, in your on-premises environment, such as OS, memory, CPU, storage capacity, and so forth. It's a quick entry to the cloud, and you can migrate them using standard practices or using something like Database Migration Service.

#### Relational databases Vs Nonrelational databases

#### Nonrelational databases

In a _nonrelational database_, you create tables. A table is a place where you can store and query data.

Nonrelational databases are sometimes referred to as "NoSQL databases" because they use structures other than rows and columns to organize data. One type of structural approach for nonrelational databases is key-value pairs. With key-value pairs, data is organized into items (keys), and items have attributes (values). You can think of attributes as being different features of your data.

In a key-value database, you can add or remove attributes from items in the table at any time. Additionally, not every item in the table has to have the same attributes.

#### Amazon RDS and Amazon DynamoDB Key Differences:

#### Amazon RDS

In the relational corner, engineered to remove undifferentiated heavy lifting from your database administrators with automatic high availability and recovery provided. You control the data, you control the schema, you control the network. You are running Amazon RDS.

#### Amazon RDS Vs Amazon DynamoDB

#### Amazon DynamoDB

The NoSQL corner, using a key value pair that requires no advanced schema, able to operate as a global database at the touch of a button. It has massive throughput. It has petabyte scale potential. It has granular API access. It is Amazon DynamoDB.

#### Use Cases

**Round One** Relational databases have been around since the moment businesses started using computers. Being able to build complex analysis of data spread across multiple tables, is the strength of any relational system. In this round, you have a sales supply chain management system that you have to analyze for weak spots. Using RDS is the clear winner here because it's built for business analytics, because you need complex relational joins. Round one easily goes to RDS.

**Round two** , the use case, pretty much anything else. Now that sounds weird, but despite what your standalone legacy database vendor would have you believe, most of what people use expensive relational databases for, has nothing to do with complex relationships. In fact, a lot of what people put into these databases ends up just being look-up tables.

imagine you have an employee contact list: names, phone numbers, emails, employee IDs. Well, this is all single table territory. I could use a relational database for this, but the things that make relational databases great, all of that complex functionality, creates overhead and lag and expense if you're not actually using it. This is where non-relational databases, Dynamo DB, delivers the knockout punch. By eliminating all the overhead, DynamoDB allows you to build powerful, incredibly fast databases where you don't need complex joint functionality. DynamoDB comes out the undisputed champion.

### Security

### Shared Responsibility Model:

- AWS is responsible for the security **of** the cloud.
- The Customer is responsible for the security **in** the cloud.

#### AWS: Security **of** the cloud

AWS is responsible for security of the cloud.

AWS operates, manages, and controls the components at all layers of infrastructure. This includes areas such as the host operating system, the virtualization layer, and even the physical security of the data centers from which services operate.

AWS is responsible for protecting the global infrastructure that runs all of the services offered in the AWS Cloud. This infrastructure includes AWS Regions, Availability Zones, and edge locations.

AWS manages the security of the cloud, specifically the physical infrastructure that hosts your resources, which include:

- Physical security of data centers
- Hardware and software infrastructure
- Network infrastructure
- Virtualization infrastructure

Although you cannot visit AWS data centers to see this protection firsthand, AWS provides several reports from third-party auditors. These auditors have verified its compliance with a variety of computer security standards and regulations.

#### Customers: Security **in** the cloud

Customers are responsible for the security of everything that they create and put in the AWS Cloud.

When using AWS services, you, the customer, maintain complete control over your content. You are responsible for managing security requirements for your content, including which content you choose to store on AWS, which AWS services you use, and who has access to that content. You also control how access rights are granted, managed, and revoked.

The security steps that you take will depend on factors such as the services that you use, the complexity of your systems, and your company's specific operational and security needs. Steps include selecting, configuring, and patching the operating systems that will run on Amazon EC2 instances, configuring security groups, and managing user accounts.

#### Amazon Web Services (AWS) Security **of** the cloud

- **Hardware** : Regions, Availability Zones, Edge Locations
- **Software** : Compute, storage, database, networking

#### Customers: Security **in** the cloud

- Client-side data encryption, server-side data encryption, and networking traffic protection
- Operating systems, and network and firewall configuration
- Platform, applications, Identity and Access Management (IAM)
- Customer data

_Encryption_ in AWS, you are the owner of your data, and you are responsible for security. That means you need to pay attention to encryption, in transit and at rest.

### Compliance

AWS has already built out data center infrastructure and networking following industry best practices for security, and as an AWS customer, you inherit all the best practices of AWS policies, architecture, and operational processes.

AWS complies with a long list of assurance programs that you can find online. This means that segments of your compliance have already been completed, and you can focus on meeting compliance within your own architectures that you build on top of AWS. The next thing to know in regards to compliance and AWS, is that the Region you choose to operate out of, might help you meet compliance regulations. If you can only legally store data in the country that the data is from, you can choose a Region that makes sense for you and AWS will not automatically replicate data across Regions.

You also should be very aware of the fact that you own your data in AWS. As shown in the AWS shared responsibility model, you have complete control over the data that you store in AWS. You can employ multiple different encryption mechanisms to keep your data safe, and that varies from service to service. So, if you need specific standards for data storage, you can devise a way to either reach those requirements by building it yourself on top of AWS or using the features that already exist in many services. For a lot of services, enabling data protection is a configuration setting on the resource.

AWS also offers multiple whitepapers and documents that you can download and use for compliance reports. Since you aren't running the data center yourself, you can essentially request that AWS provides you with documentation proving that they are following best practices for security and compliance.

#### AWS Compliance Center

Check out the AWS Compliance Center in order to find compliance information all in one place. It will show you compliance enabling services as well as documentation like the AWS Risk and Security Whitepaper, which you should read to ensure that you understand security and compliance with AWS.

we follow a shared responsibility. The underlying platform is secure and AWS can provide documentation on what types of compliance requirements they meet, through services like AWS Artifact and whitepapers. But, beyond that, what you build on AWS is up to you. You control the architecture of your applications and the solutions you build, and they need to be built with compliance, security, and the shared responsibility model in mind.

_AWS compliance uses third-party auditors_ to prove its adherence to a wide variety of compliance programs. You can use the AWS Compliance Center to find more information on compliance and AWS Artifact to gain access to compliance documents. The compliance requirements you have will vary from application to application and between areas of operation.

#### Denial-of-Service Attacks

A _denial-of-service (DoS) attack_ is a deliberate attempt to make a website or application unavailable to users.

In a _distributed denial-of-service (DDoS)_ attack, multiple sources are used to start an attack that aims to make a website or application unavailable. This can come from a group of attackers, or even a single attacker. The single attacker can use multiple infected computers (also known as "bots") to send excessive traffic to a website or application.

To help minimize the effect of DoS and DDoS attacks on your applications, you can use AWS Shield.

_Distributed denial-of-service attacks_, or DDoS attacks, and how to combat them with AWS using tools like ELB, security groups, AWS Shield, and AWS WAF.

### IAM

With _IAM_, you have users, groups, roles, and policies. Users log in with a username and password and by default they have no permissions. Groups are groupings of users and roles are identities that you can assume to gain access to temporary credentials and permissions for a configurable amount of time. In order to give permissions to an identity, you need to create policies that either explicitly allow or deny a specific action in AWS. _With IAM also comes identity federation_. If you have an existing corporate identity store, you can federate those users to AWS, using role based access, which allows your users to use one login for both your corporate systems as well as AWS. One final point to remember about IAM is that you should make sure that you turn on _multi-factor Authentication_ for users, but especially for your root user which has all the permissions by default and cannot be restricted.

_AWS Organizations_. With AWS, it's likely you'll have multiple accounts. Accounts are commonly used to isolate workloads, environments, teams, or applications. AWS Organizations helps you manage multiple accounts in a hierarchical fashion.

Use the _least privilege principle_ when scoping permissions for users and roles in IAM, encrypt your data at every layer, both in transit and at rest. And make sure you use AWS services to protect your environment.

### Monitoring and Analytics

#### Example: AWS CloudTrail event

Suppose that the coffee shop owner is browsing through the AWS Identity and Access Management (IAM) section of the AWS Management Console. They discover that a new IAM user named Mary was created, but they do not know who, when, or which method created the user.

To answer these questions, the owner navigates to AWS CloudTrail.

In the CloudTrail Event History section, the owner applies a filter to display only the events for the "CreateUser" API action in IAM. The owner locates the event for the API call that created an IAM user for Mary. This event record provides complete details about what occurred:

On January 1, 2020 at 9:00 AM, IAM user John created a new IAM user (Mary) through the AWS Management Console.

_CloudWatch_ can provide near real-time understanding of how your system is behaving, including being alerted to conditions that require your attention. CloudWatch also gives you the ability to look at those metrics over time as you tune your system for maximum performance.

_CloudTrail_ can help you know exactly who did what, when, and from where. It answers all of your AWS auditing questions, except why they did it.

_Trusted Advisor_ that compiles a quick dashboard of over 40 common concerns around cost, performance, security, and resilience in an actionable dashboard. AWS Trusted Advisor is a web service that inspects your AWS environment and provides real-time recommendations in accordance with AWS best practices. The inspection includes security checks, such as Amazon S3 buckets with open access permissions.

### Pricing and Support

### Pricing

#### AWS Free Tier

_The AWS Free Tier_ enables you to begin using certain services without having to worry about incurring costs for the specified period.

Three types of offers are available:

- Always Free
- 12 Months Free
- Trials

_Always Free_ These offers do not expire and are available to all AWS customers. For example, AWS Lambda allows 1 million free requests and up to 3.2 million seconds of compute time per month. Amazon DynamoDB allows 25 GB of free storage per month.

_12 Months Free_ These offers are free for 12 months following your initial sign-up date to AWS. Examples include specific amounts of Amazon S3 Standard Storage, thresholds for monthly hours of Amazon EC2 compute time, and amounts of Amazon CloudFront data transfer out.

_Trials_ Short-term free trial offers start from the date you activate a particular service. The length of each trial might vary by number of days or the amount of usage in the service. For example, Amazon Inspector offers a 90-day free trial. Amazon Lightsail (a service that enables you to run virtual private servers) offers 750 free hours of usage over a 30-day period.

#### _Pay for what you use_

For each service, you pay for exactly the amount of resources that you actually use, without requiring long-term contracts or complex licensing.

#### _Pay less when you reserve._

Some services offer reservation options that provide a significant discount compared to On-Demand Instance pricing.

For example, suppose that your company is using Amazon EC2 instances for a workload that needs to run continuously. You might choose to run this workload on Amazon EC2 Instance Savings Plans, because the plan allows you to save up to 72% over the equivalent On-Demand Instance capacity.

#### Pay less with volume-based discounts when you use more.

Some services offer tiered pricing, so the per-unit cost is incrementally lower with increased usage. For example, the more Amazon S3 storage space you use, the less you pay for it per GB.

#### AWS Pricing Calculator

_The AWS Pricing Calculator_ lets you explore AWS services and create an estimate for the cost of your use cases on AWS. You can organize your AWS estimates by groups that you define. A group can reflect how your company is organized, such as providing estimates by cost center. When you have created an estimate, you can save it and generate a link to share it with others.

Suppose that your company is interested in using Amazon EC2. However, you are not yet sure which AWS Region or instance type would be the most cost-efficient for your use case. In the AWS Pricing Calculator, you can enter details, such as the kind of operating system you need, memory requirements, and input/output (I/O) requirements. By using the AWS Pricing Calculator, you can review an estimated comparison of different EC2 instance types across AWS Regions.

#### Pricing Examples:

For _Pricing AWS Lambda_, you are charged based on the number of requests for your functions and the time that it takes for them to run. AWS Lambda allows 1 million free requests and up to 3.2 million seconds of compute time per month. You can save on AWS Lambda costs by signing up for a Compute Savings Plan. A Compute Savings Plan offers lower compute costs in exchange for committing to a consistent amount of usage over a 1-year or 3-year term. This is an example of paying less when you reserve.

With _Pricing Amazon EC2_, you pay for only the compute time that you use while your instances are running. For some workloads, you can significantly reduce Amazon EC2 costs by using Spot Instances. For example, suppose that you are running a batch processing job that is able to withstand interruptions. Using a Spot Instance would provide you with up to 90% cost savings while still meeting the availability requirements of your workload. You can find additional cost savings for Amazon EC2 by considering Savings Plans and Reserved Instances.

For _Amazon S3 pricing_, consider the following cost components:

**Storage** - You pay for only the storage that you use. You are charged the rate to store objects in your Amazon S3 buckets based on your objects' sizes, storage classes, and how long you have stored each object during the month.

**Requests and data retrievals** - You pay for requests made to your Amazon S3 objects and buckets. For example, suppose that you are storing photo files in Amazon S3 buckets and hosting them on a website. Every time a visitor requests the website that includes these photo files, this counts towards requests you must pay for.

**Data transfer** - There is no cost to transfer data between different Amazon S3 buckets or from Amazon S3 to other services within the same AWS Region. However, you pay for data that you transfer into and out of Amazon S3, with a few exceptions. There is no cost for data transferred into Amazon S3 from the internet or out to Amazon CloudFront. There is also no cost for data transferred out to an Amazon EC2 instance in the same AWS Region as the Amazon S3 bucket.

**Management and replication** - You pay for the storage management features that you have enabled on your account's Amazon S3 buckets. These features include Amazon S3 inventory, analytics, and object tagging.

_AWS Billing & Cost Management dashboard_ to pay your AWS bill, monitor your usage, and analyze and control your costs.

- Compare your current month-to-date balance with the previous month, and get a forecast of the next month based on current usage.
- View month-to-date spend by service.
- View Free Tier usage by service.
- Access Cost Explorer and create budgets.
- Purchase and manage Savings Plans.
- Publish AWS Cost and Usage Reports

### Support Plans

#### AWS Support

AWS offers four different Support plans(opens in a new tab) to help you troubleshoot issues, lower costs, and efficiently use AWS services.

You can choose from the following Support plans to meet your company's needs:

- Basic
- Developer
- Business
- Enterprise On-Ramp
- Enterprise

#### Basic Support

Basic Support is free for all AWS customers. It includes access to whitepapers, documentation, and support communities. With Basic Support, you can also contact AWS for billing questions and service limit increases.

With Basic Support, you have access to a limited selection of AWS Trusted Advisor checks. Additionally, you can use the AWS Personal Health Dashboard, a tool that provides alerts and remediation guidance when AWS is experiencing events that may affect you.

If your company needs support beyond the Basic level, you could consider purchasing Developer, Business, Enterprise On-Ramp, and Enterprise Support.

#### Developer Support

Customers in the Developer Support plan have access to features such as:

- Best practice guidance
- Client-side diagnostic tools
- Building-block architecture support, which consists of guidance for how to use AWS offerings, features, and services together

For example, suppose that your company is exploring AWS services. You've heard about a few different AWS services. However, you're unsure of how to potentially use them together to build applications that can address your company's needs. In this scenario, the building-block architecture support that is included with the Developer Support plan could help you to identify opportunities for combining specific services and features.

#### Business Support

Customers with a Business Support plan have access to additional features, including:

- Use-case guidance to identify AWS offerings, features, and services that can best support your specific needs
- All AWS Trusted Advisor checks
- Limited support for third-party software, such as common operating systems and application stack components

Suppose that your company has the Business Support plan and wants to install a common third-party operating system onto your Amazon EC2 instances. You could contact AWS Support for assistance with installing, configuring, and troubleshooting the operating system. For advanced topics such as optimizing performance, using custom scripts, or resolving security issues, you may need to contact the third-party software provider directly.

#### Enterprise On-Ramp Support

In November 2021, AWS opened enrollment into AWS Enterprise On-Ramp Support plan. In addition to all the features included in the Basic, Developer, and Business Support plans, customers with an Enterprise On-Ramp Support plan have access to:

- A pool of Technical Account Managers to provide proactive guidance and coordinate access to programs and AWS experts
- A Cost Optimization workshop (one per year)
- A Concierge support team for billing and account assistance
- Tools to monitor costs and performance through Trusted Advisor and Health API/Dashboard

Enterprise On-Ramp Support plan also provides access to a specific set of proactive support services, which are provided by a pool of Technical Account Managers.

- Consultative review and architecture guidance (one per year)
- Infrastructure Event Management support (one per year)
- Support automation workflows
- 30 minutes or less response time for business-critical issues

#### Enterprise Support

In addition to all features included in the Basic, Developer, Business, and Enterprise On-Ramp support plans, customers with Enterprise Support have access to:

- A designated Technical Account Manager to provide proactive guidance and coordinate access to programs and AWS experts
- A Concierge support team for billing and account assistance
- Operations Reviews and tools to monitor health
- Training and Game Days to drive innovation
- Tools to monitor costs and performance through Trusted Advisor and Health API/Dashboard

The Enterprise plan also provides full access to proactive services, which are provided by a designated Technical Account Manager:

- Consultative review and architecture guidance
- Infrastructure Event Management support
- Cost Optimization Workshop and tools
- Support automation workflows
- 15 minutes or less response time for business-critical issues

#### Developer, Business, Enterprise On-Ramp, and Enterprise Support

The Developer, Business, Enterprise On-Ramp, and Enterprise Support plans include all the benefits of Basic Support, in addition to the ability to open an unrestricted number of technical support cases. These Support plans have pay-by-the-month pricing and require no long-term contracts.

The information in this course highlights only a selection of details for each Support plan. A complete overview of what is included in each Support plan, including pricing for each plan, is available on the AWS Support site.

In general, for pricing, the Developer plan has the lowest cost, the Business and Enterprise On-Ramp plans are in the middle, and the Enterprise plan has the highest cost.

#### Technical Account Manager (TAM)

The Enterprise On-Ramp and Enterprise Support plans include access to a Technical Account Manager (TAM).

The TAM is your primary point of contact at AWS. If your company subscribes to Enterprise Support or Enterprise On-Ramp, your TAM educates, empowers, and evolves your cloud journey across the full range of AWS services. TAMs provide expert engineering guidance, help you design solutions that efficiently integrate AWS services, assist with cost-effective and resilient architectures, and provide direct access to AWS programs and a broad community of experts.

For example, suppose that you are interested in developing an application that uses several AWS services together. Your TAM could provide insights into how to best use the services together. They achieve this, while aligning with the specific needs that your company is hoping to address through the new application.

### Migration and Innovation

#### AWS Cloud Adoption Framework

The Cloud Adoption Framework exists to provide advice to your company to enable a quick and smooth migration to AWS.

The different Perspectives are Business, People, and Governance Perspectives, which focus on the business capabilities, and then you have the Platform, Security and Operations Perspectives which focus on the technical capabilities.

Each Perspective is used to uncover gaps in your skills and processes, which are then recorded as inputs. These inputs are then used as the basis for creating what is called an AWS Cloud Adoption Framework Action Plan that you then use to guide your organization's change management as you journey to the cloud. Having an action plan that makes sense for your organization can help keep you on track. Migrating to the cloud can be complicated, but again, you're not alone in this, there are tons of resources to help you get started, and the Cloud Adoption Framework is a great place to look.

#### Business Perspective

The Business Perspective ensures that IT aligns with business needs and that IT investments link to key business results. Use the Business Perspective to create a strong business case for cloud adoption and prioritize cloud adoption initiatives. Ensure that your business strategies and goals align with your IT strategies and goals.

Common roles in the Business Perspective include:

- Business managers
- Finance managers
- Budget owners
- Strategy stakeholders

#### People Perspective

The People Perspective supports development of an organization-wide change management strategy for successful cloud adoption. Use the People Perspective to evaluate organizational structures and roles, new skill and process requirements, and identify gaps. This helps prioritize training, staffing, and organizational changes.

Common roles in the People Perspective include:

- Human resources
- Staffing
- People managers

#### Governance Perspective

The Governance Perspective focuses on the skills and processes to align IT strategy with business strategy. This ensures that you maximize the business value and minimize risks. Use the Governance Perspective to understand how to update the staff skills and processes necessary to ensure business governance in the cloud. Manage and measure cloud investments to evaluate business outcomes.

Common roles in the Governance Perspective include:

- Chief Information Officer (CIO)
- Program managers
- Enterprise architects
- Business analysts
- Portfolio managers

#### Platform Perspective

The Platform Perspective includes principles and patterns for implementing new solutions on the cloud, and migrating on-premises workloads to the cloud. Use a variety of architectural models to understand and communicate the structure of IT systems and their relationships. Describe the architecture of the target state environment in detail.

Common roles in the Platform Perspective include:

- Chief Technology Officer (CTO)
- IT managers
- Solutions architects

#### Security Perspective

The Security Perspective ensures that the organization meets security objectives for visibility, auditability, control, and agility. Use the AWS CAF to structure the selection and implementation of security controls that meet the organization's needs.

Common roles in the Security Perspective include:

- Chief Information Security Officer (CISO)
- IT security managers
- IT security analysts

#### Operations Perspective

The Operations Perspective helps you to enable, run, use, operate, and recover IT workloads to the level agreed upon with your business stakeholders. Define how day-to-day, quarter-to-quarter, and year-to-year business is conducted. Align with and support the operations of the business. The AWS CAF helps these stakeholders define current operating procedures and identify the process changes and training needed to implement successful cloud adoption.

Common roles in the Operations Perspective include:

- IT operations managers
- IT support managers

### Migration Strategies

#### 7 strategies for migration

When migrating applications to the cloud, 7 of the most common migration strategies(opens in a new tab) that you can implement are:

- Rehosting
- Replatforming
- Refactoring/re-architecting
- Repurchasing
- Relocate
- Retaining
- Retiring

_Rehosting_ This is otherwise known as **lift and shift**. And this is an easy thing for businesses to do because you're not making any changes. At least not at first. Just pick up the applications and move them pretty much as is onto AWS. You may not get all the possible benefits. But some companies found that even without any optimization, they could save up to 30% of their total costs just by rehosting. Also, we find it's easier to optimize applications later once they already live in the cloud. Because your organization has better skills to do so. The hard part, the migration, is already complete.

_Replatforming_ Or **lift, tinker, and shift**. It's still basically a lift and shift, but instead of a pure one-to-one, you might make a few cloud optimizations. But you're not touching any core code in the process. No new dev efforts are involved here. For example, you could take your existing MySQL database and replatform it onto RDS MySQL, without any code changes at all. Or even consider upgrading to Amazon Aurora. This gives significant benefit to your DBA team as well as improved performance without any code changes.

_Retire_ Some parts of your enterprise IT portfolio are just no longer needed. We found as much as 10% to 20% of companies application portfolios include applications that are no longer being used or already have replacements live and functional. Using the AWS migration plan as the opportunity to actually **end-of-life** these applications can save significant cost and effort for your team. Sometimes you just have to turn off the lights.

_Retain_ Some applications are about to be deprecated but maybe not just yet. They still need to run but don't turn them off for another three months or eight months. These apps could be migrated to AWS, but why? You should only migrate what makes sense for your business. And then as time goes on, these applications can be deprecated where they live, and ultimately retired.

_Repurchase_ This is common for companies looking to abandon legacy software vendors and get a fresh start as part of migration. For example, ending a contract with an old CRM vendor and moving to a brand new one. Or perhaps finally ending your licensing with an out of date database vendor in favor of cloud native database offerings. Now, this sounds great, but remember, you'll now be dealing with a new software package and some are easy to implement, some take time. The total upfront expense of the step therefore goes up, but the potential benefits could be substantial.

_Refactoring_**(also known as re-architecting**) Now, you're writing new code. This is driven by a strong business need to add features or performance that might not be possible on prem, but now are within your reach. Dramatic changes to your architecture can be very beneficial to your enterprise but this will come at the highest initial cost in terms of planning and human effort.

### The Cloud Journey

### The AWS Well-Architected Framework

The _AWS Well-Architected Framework_ helps you understand how to design and operate reliable, secure, efficient, and cost-effective systems in the AWS Cloud. It provides a way for you to consistently measure your architecture against best practices and design principles and identify areas for improvement.

#### The Well-Architected Framework is based on six pillars:

- Operational excellence
- Security
- Reliability
- Performance efficiency
- Cost optimization
- Sustainability

_Operational excellence Pillar_ is the ability to run and monitor systems to deliver business value and to continually improve supporting processes and procedures.

Design principles for operational excellence in the cloud include performing operations as code, annotating documentation, anticipating failure, and frequently making small, reversible changes.

The _Security pillar_ is the ability to protect information, systems, and assets while delivering business value through risk assessments and mitigation strategies.

When considering the security of your architecture, apply these best practices:

- Automate security best practices when possible.
- Apply security at all layers.
- Protect data in transit and at rest.

_Reliability Pillar_ is the ability of a system to do the following:

- Recover from infrastructure or service disruptions
- Dynamically acquire computing resources to meet demand
- Mitigate disruptions such as misconfigurations or transient network issues

Reliability includes testing recovery procedures, scaling horizontally to increase aggregate system availability, and automatically recovering from failure.

_Performance efficiency Pillar_ is the ability to use computing resources efficiently to meet system requirements and to maintain that efficiency as demand changes and technologies evolve.

Evaluating the performance efficiency of your architecture includes experimenting more often, using serverless architectures, and designing systems to be able to go global in minutes.

_Cost optimization Pillar_ is the ability to run systems to deliver business value at the lowest price point.

Cost optimization includes adopting a consumption model, analyzing and attributing expenditure, and using managed services to reduce the cost of ownership.

_Sustainability Pillar_ is the ability to continually improve sustainability impacts by reducing energy consumption and increasing efficiency across all components of a workload by maximizing the benefits from the provisioned resources and minimizing the total resources required.

To facilitate good design for sustainability:

- Understand your impact
- Establish sustainability goals
- Maximize utilization
- Anticipate and adopt new, more efficient hardware and software offerings
- Use managed services
- Reduce the downstream impact of your cloud workloads

![](RackMultipart20231220-1-b07fzm_html_353ef36053907da7.png)
